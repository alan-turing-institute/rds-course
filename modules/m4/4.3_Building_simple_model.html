
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>4.3 Building a simple model &#8212; Research Data Science</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe,.cell"
        const thebe_selector_input = "pre,.cell_input div.highlight"
        const thebe_selector_output = ".output,.cell_output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="4.4 Evaluating models" href="4.4_Evaluating_a_model.html" />
    <link rel="prev" title="4.2 Fitting (Regression) Models" href="4.2_Fitting_Models.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Research Data Science</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../index.html">
   Welcome to The Alan Turing Institute’s Introduction to Research Data Science course
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Module 1: Introduction to Data Science
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../m1/overview.html">
   Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../m1/1.1-WhatIsDataScience.html">
   1.1 What is (research) data science?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../m1/1.2-DataScienceProjectLifecycle.html">
   1.2 Research Data Science project lifecycle
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../m1/1.3-EDIForDataScience.html">
   1.3 Equality, diversity and inclusion in data science
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../m1/1.4-CollaborationAndReproducibility.html">
   1.4 Collaboration and reproducibility
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../m1/hands-on.html">
   Module 1: Hands-on session
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Module 2: Handling data
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../m2/2-overview.html">
   Overview
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../m2/2-01-GettingLoading.html">
   2.1 Getting and Loading Data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../m2/2-01-01-WhereToFindData.html">
     2.1.1 Where to find data?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../m2/2-01-02-LegalityAndEthics.html">
     2.1.2 Legality and Ethics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../m2/2-01-03-PandasIntro.html">
     2.1.3 Pandas intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../m2/2-01-04-DataSourcesAndFormats.html">
     2.1.4 Data Sources and Formats
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../m2/2-01-05-ControllingAccess.html">
     2.1.5 Controlling access
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../m2/2-02-ExploringWrangling.html">
   2.2 Exploring and Wrangling Data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../m2/2-02-01-DataConsistency.html">
     2.2.1 Data Consistency
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../m2/2-02-02-ModifyingColumnsAndIndices.html">
     2.2.2 Modifying Columns and Indices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../m2/2-02-03-FeatureEngineering.html">
     2.2.3 Feature Engineering
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../m2/2-02-04-DataManipulation.html">
     2.2.4 Data Manipulation
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../m2/2-02-04-01-TimeAndDateData.html">
       2.2.4.1 Time and Date Data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../m2/2-02-04-02-TextData.html">
       2.2.4.2 Text data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../m2/2-02-04-03-CategoricalData.html">
       2.2.4.3 Categorical Data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../m2/2-02-04-04-ImageData.html">
       2.2.4.4 Image Data
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../m2/2-02-05-PrivacyAndAnonymisation.html">
     2.2.5 Privacy and Anonymisation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../m2/2-02-06-LinkingDatasets.html">
     2.2.6 Linking Datasets
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../m2/2-02-07-MissingData.html">
     2.2.7 Missing Data
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../m2/2-hands-on.html">
   Module 2: Hands-on session
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../m2/2-hands-on-complete.html">
   Module 2: Hands-on session (Solutions)
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Module 3: Data Visualisation &amp; Exploration
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../m3/overview.html">
   Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../m3/3.1-FiguresGoneWrong.html">
   3.1 Figures gone wrong
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../m3/3.2-RulesOfTheGame.html">
   3.2 Rules of the data visualisation game
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../m3/3.3-Atlas0fVisualisations.html">
   3.3 Atlas of Visualisations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../m3/3.4-StoryTelling.html">
   3.4 Storytelling with data visualisation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../m3/3.5-DataVisForExploration.html">
   3.5 Walkthrough: visualisation for data exploration
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../m3/hands-on.html">
   Module 3 hands-on session
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Module 4: Introduction to Modelling
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="overview.html">
   Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="4.1_What_and_Why.html">
   4.1 The What and Why of Statistical Modelling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="4.2_Fitting_Models.html">
   4.2 Fitting (Regression) Models
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   4.3 Building a simple model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="4.4_Evaluating_a_model.html">
   4.4 Evaluating models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="hands-on.html">
   Module 4 hands-on session
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/modules/m4/4.3_Building_simple_model.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/alan-turing-institute/rds-course"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/alan-turing-institute/rds-course/issues/new?title=Issue%20on%20page%20%2Fmodules/m4/4.3_Building_simple_model.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/alan-turing-institute/rds-course/develop?urlpath=tree/coursebook/modules/m4/4.3_Building_simple_model.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <button type="button" class="btn btn-secondary topbarbtn"
            onclick="initThebeSBT()" title="Launch Thebe" data-toggle="tooltip" data-placement="left"><i
                class="fas fa-play"></i><span style="margin-left: .4em;">Live Code</span></button>
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   4.3 Building a simple model
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#recap">
     Recap
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#data-processing">
     Data processing
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#logistic-regression">
     Logistic regression
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#simple-model-1-modelling-the-self-reported-health-as-a-function-of-the-deprivation-index">
     Simple model 1: modelling the Self-reported Health as a function of the Deprivation Index
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#simple-model-2-modelling-srh-as-a-function-of-deprivation-and-age">
   Simple model 2: modelling SRH as a function of deprivation and age
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="building-a-simple-model">
<span id="section4-3"></span><h1>4.3 Building a simple model<a class="headerlink" href="#building-a-simple-model" title="Permalink to this headline">¶</a></h1>
<p>In this section we will use what we’ve learned in <a class="reference internal" href="4.1_What_and_Why.html#section4-1"><span class="std std-ref"><em>Section 4.1</em></span></a> and <a class="reference internal" href="4.2_Fitting_Models.html#section4-2"><span class="std std-ref"><em>Section 4.2</em></span></a> to begin modelling the EQLS dataset.</p>
<div class="section" id="recap">
<h2>Recap<a class="headerlink" href="#recap" title="Permalink to this headline">¶</a></h2>
<p>In <span class="xref myst"><em>Section 3.5</em></span> we selected some interesting variables and looked at some of the relationships - in particular, in our <em>material</em> variables <code class="docutils literal notranslate"><span class="pre">DeprIndex</span></code> and <code class="docutils literal notranslate"><span class="pre">AccomProblems</span></code>. We also visualised the distribution of the Deprivation Index (<code class="docutils literal notranslate"><span class="pre">DeprIndex</span></code>) for different categories of the self-reported Health (<code class="docutils literal notranslate"><span class="pre">SRH</span></code>) and found that there was an obvious relationship between these variables. Furthermore, following previous research done on the topic (and also for simplicity), we decided to binarise our variable of interest <code class="docutils literal notranslate"><span class="pre">SRH</span></code> in two categories of <code class="docutils literal notranslate"><span class="pre">Fair</span></code> and <code class="docutils literal notranslate"><span class="pre">Poor</span></code> health.</p>
</div>
<div class="section" id="data-processing">
<h2>Data processing<a class="headerlink" href="#data-processing" title="Permalink to this headline">¶</a></h2>
<p>Let’s start building a simple model attempting to predict <code class="docutils literal notranslate"><span class="pre">SRH</span></code> using <code class="docutils literal notranslate"><span class="pre">DeprIndex</span></code> using data from the UK.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
 
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;seaborn&#39;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_theme</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s2">&quot;whitegrid&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s2">&quot;white&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>First  let’s load the data in the same way as we did in <span class="xref myst"><em>Section 3.5</em></span>. We can access the data by downloading the <a class="reference external" href="https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=7724#%21/details">csv</a> option from here.</p>
<p>Unzip the data to <code class="docutils literal notranslate"><span class="pre">$PROJECT_ROOT/data</span></code> (where <code class="docutils literal notranslate"><span class="pre">$PROJECT_ROOT</span></code> is the root of the cloned github repository for this course).
This should give you <code class="docutils literal notranslate"><span class="pre">$PROJECT_ROOT/data/UKDA-7724-csv</span></code> directory.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">datafolder</span> <span class="o">=</span> <span class="s1">&#39;../../../data/UKDA-7724-csv/&#39;</span> <span class="c1"># should match the path you unzipped the data to</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">datafolder</span> <span class="o">+</span> <span class="s1">&#39;csv/eqls_2011.csv&#39;</span><span class="p">)</span>
<span class="n">df_map</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">datafolder</span> <span class="o">+</span> <span class="s1">&#39;mrdoc/excel/eqls_api_map.csv&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;latin1&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># we are only interested in the UK for this example.</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s1">&#39;Y11_Country == 27&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>To make the manipulation easier we select a subset of the data with only the variables we want and rename them into something more readable.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">var_map</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;Y11_Q42&quot;</span><span class="p">:</span> <span class="s2">&quot;SRH&quot;</span><span class="p">,</span>
           <span class="s1">&#39;Y11_Deprindex&#39;</span><span class="p">:</span> <span class="s1">&#39;DeprIndex&#39;</span><span class="p">,</span>
           <span class="s2">&quot;Y11_Accommproblems&quot;</span><span class="p">:</span> <span class="s1">&#39;AccomProblems&#39;</span><span class="p">,</span>
           <span class="s2">&quot;Y11_Incomequartiles_percapita&quot;</span> <span class="p">:</span> <span class="s2">&quot;IncomeQuartiles&quot;</span><span class="p">,</span>
           <span class="s2">&quot;Y11_HHsize&quot;</span><span class="p">:</span> <span class="s2">&quot;HouseholdSize&quot;</span><span class="p">,</span>
           <span class="s2">&quot;Y11_Q32&quot;</span><span class="p">:</span> <span class="s2">&quot;Children&quot;</span><span class="p">,</span>
           <span class="s2">&quot;DV_Q7&quot;</span><span class="p">:</span><span class="s2">&quot;WorkingHours&quot;</span><span class="p">,</span>
           <span class="s2">&quot;Y11_ISCEDsimple&quot;</span><span class="p">:</span><span class="s2">&quot;ISCED&quot;</span><span class="p">,</span>
           <span class="s2">&quot;Y11_SocExIndex&quot;</span><span class="p">:</span><span class="s2">&quot;SocialExclusionIndex&quot;</span><span class="p">,</span>
           <span class="s2">&quot;Y11_MWIndex&quot;</span><span class="p">:</span> <span class="s2">&quot;MentalWellbeingIndex&quot;</span><span class="p">,</span>
           <span class="s2">&quot;Y11_Agecategory&quot;</span><span class="p">:</span><span class="s2">&quot;AgeCategory&quot;</span><span class="p">,</span>
           <span class="s2">&quot;Y11_HH2a&quot;</span><span class="p">:</span><span class="s2">&quot;Gender&quot;</span><span class="p">,</span>
           <span class="s2">&quot;Y11_Q31&quot;</span><span class="p">:</span><span class="s2">&quot;MaritalStatus&quot;</span><span class="p">,</span>
           <span class="s2">&quot;Y11_Country&quot;</span><span class="p">:</span><span class="s2">&quot;Country&quot;</span>
<span class="p">}</span>

<span class="n">df</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">var_map</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df_set</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">var_map</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>
</pre></div>
</div>
</div>
</div>
<p>In <em>Section 3.5</em> we realised that variables like <code class="docutils literal notranslate"><span class="pre">WorkingHours</span></code>, <code class="docutils literal notranslate"><span class="pre">IncomeQuartiles</span></code> have a lot of missing data, so we decided to not use them in the modeling. Furthermore, we dropped the remaining rows with missing data (<strong>warning</strong>: this shouldn’t be done lightly without having explored the missingness of the data, here we are doing for simplicity and to focus on the modelling).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_model</span> <span class="o">=</span> <span class="n">df_set</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;WorkingHours&#39;</span><span class="p">,</span><span class="s1">&#39;IncomeQuartiles&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span> <span class="c1">#we defer imputation to a later date. For now we remove na.</span>
</pre></div>
</div>
</div>
</div>
<p>Finally, we must dichotomise our <code class="docutils literal notranslate"><span class="pre">SRH</span></code> variable.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># dichotomise SRH</span>
<span class="n">df_model</span><span class="p">[</span><span class="s1">&#39;SRH_binary&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_model</span><span class="o">.</span><span class="n">SRH</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">1</span> <span class="k">if</span> <span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">3</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="logistic-regression">
<h2>Logistic regression<a class="headerlink" href="#logistic-regression" title="Permalink to this headline">¶</a></h2>
<p>We want to predict the probability of SRH being 1 (i.e good health). In <a class="reference internal" href="4.2_Fitting_Models.html#section4-2"><span class="std std-ref"><em>Section 4.2</em></span></a> we saw that we do this by predicting the log-odds of <span class="math notranslate nohighlight">\(p(x)\)</span>. Why?</p>
<p>The odds of something are the probability of it happening divided by the probability of it not happening:</p>
<div class="math notranslate nohighlight">
\[ odds(x) = \frac{p(x)}{1 - p(x)} \]</div>
<p>Let’s have a simple example. Say you have a bag of 5 balls, with 4 red and 1 blue. The probability of drawing a red ball is <span class="math notranslate nohighlight">\(\frac{4}{5}\)</span>, and the probability of drawing a blue ball is <span class="math notranslate nohighlight">\(\frac{1}{5}\)</span>. The probability of drawing a blue ball is the same as the probability of <em>not drawing a red ball</em>, which is <span class="math notranslate nohighlight">\(1-P(red) = 1-\frac{4}{5} = \frac{1}{5}\)</span>.</p>
<p>Now, the odds of drawing a red ball is related but not identical to the probability of drawing of a red ball. Instead, it is a measure of how likely drawing a red ball is <em>in comparison to</em> not drawing a red ball. In our simple example we can see the difference. There are four times as many red balls as blue, so you are four times as likely to draw one. The probability, in contrast, is 80%.</p>
<p>So:</p>
<div class="math notranslate nohighlight">
\[ odds(red) = \frac{P(red)}{1-P(red)} = \frac{\frac{4}{5}}{1-\frac{4}{5}} = \frac{\frac{4}{5}}{\frac{1}{5}} = 4 \]</div>
<p><strong>Why do we use log(odds)?</strong></p>
<p>The left side of the figure below shows the odds of a binary outcome with different probabilities for p(x). You can see that as <span class="math notranslate nohighlight">\(p(x)\)</span> becomes closer to 1, <span class="math notranslate nohighlight">\(1-p(x)\)</span> becomes infinitesimal, so the odds tend towards infinitely large.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">.01</span><span class="p">,</span><span class="mf">.99</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
<span class="n">odds</span> <span class="o">=</span> <span class="n">p</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">p</span><span class="p">)</span>

<span class="n">g</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">JointGrid</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">p</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">odds</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">g</span><span class="o">.</span><span class="n">ax_joint</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">odds</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">g</span><span class="o">.</span><span class="n">ax_marg_y</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">ax_marg_x</span><span class="o">.</span><span class="n">set_axis_off</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;p(x)&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;odds&#39;</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span> <span class="s1">&#39;p(x) vs odds&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/4.3_Building_simple_model_12_0.png" src="../../_images/4.3_Building_simple_model_12_0.png" />
</div>
</div>
<p>In regression we want equal probability to be placed to either side of the odds function. Taking the log-odds transforms the exponential odds into a symmetrical and continuous function.
As shown below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">g</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">JointGrid</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span><span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">p</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">odds</span><span class="p">),</span> <span class="n">ax</span><span class="o">=</span><span class="n">g</span><span class="o">.</span><span class="n">ax_joint</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">odds</span><span class="p">),</span> <span class="n">ax</span><span class="o">=</span><span class="n">g</span><span class="o">.</span><span class="n">ax_marg_y</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">ax_marg_x</span><span class="o">.</span><span class="n">set_axis_off</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;p(x)&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;log(odds)&#39;</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span> <span class="s1">&#39;p(x) vs log(odds)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/4.3_Building_simple_model_14_0.png" src="../../_images/4.3_Building_simple_model_14_0.png" />
</div>
</div>
<p>Using log-odds gives us the logistic regression formula from <a class="reference internal" href="4.2_Fitting_Models.html#section4-2"><span class="std std-ref"><em>Section 4.2</em></span></a>:</p>
<div class="math notranslate nohighlight">
\[
\log\left(\frac{p({\bf x})}{1 - p({\bf x})}\right) = \beta_0 + \beta_1 x_1 + \ldots  + \beta_{n} x_{n}
\]</div>
<p><strong>Classifying log-odds</strong></p>
<p>The log-odds of <span class="math notranslate nohighlight">\(x\)</span> are also referred to by the function <span class="math notranslate nohighlight">\(logit(x)\)</span>. We have shown that from <span class="math notranslate nohighlight">\(p(x)\)</span> we can get <span class="math notranslate nohighlight">\(logit(x)\)</span>. To convert <span class="math notranslate nohighlight">\(logit(x)\)</span> into a categorical variable <span class="math notranslate nohighlight">\(y={0,1}\)</span> we need a probability, let’s call it <span class="math notranslate nohighlight">\(\hat{p}\)</span>, so that we can state that if <span class="math notranslate nohighlight">\(\hat{p}\geq0.5\)</span> then <span class="math notranslate nohighlight">\(y=1\)</span>.</p>
<p>The <strong>sigmoid</strong> function is the inverse of the logit function. If we say that the output of <span class="math notranslate nohighlight">\(logit(x)\)</span> is <span class="math notranslate nohighlight">\(\hat{x}\)</span>, then:</p>
<div class="math notranslate nohighlight">
\[ \frac{1}{1 + e^{-\hat{x}}} \]</div>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<div class="dropdown tip admonition">
<p class="admonition-title">Sigmoid intuition</p>
<p>The intuition for the sigmoind function is as follows.</p>
<ul class="simple">
<li><p>A fraction with <span class="math notranslate nohighlight">\(1\)</span> as the numerator always has a maximum of <span class="math notranslate nohighlight">\(1/1 = 1\)</span>. As the denominator grows, the value gets closer to <span class="math notranslate nohighlight">\(0\)</span>, but never below it.</p></li>
<li><p><span class="math notranslate nohighlight">\(x^{-y}  = \frac{1}{x^y}\)</span>, so <span class="math notranslate nohighlight">\(e^{-\hat{x}} = \frac{1}{e^{\hat{x}}}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(e^{log(odds)} = odds\)</span> So <span class="math notranslate nohighlight">\(e^{-log(odds)} = \frac{1}{odds}\)</span>. The inverse of the odds how more likely an event is to <em>not</em> happen.</p></li>
<li><p>So, the sigmoid function is actually <span class="math notranslate nohighlight">\(\frac{1}{1+\frac{1}{odds}}\)</span>. In other words, when the odds are high the sigmoid function is close to 1, as they decrease the sigmoid function goes towards zero, bounded by zero and 1.</p></li>
<li><p>This latter function cancels out to <span class="math notranslate nohighlight">\(p(x)\)</span>.</p></li>
</ul>
</div>
</div>
<p>Now, let’s return to modelling our data.</p>
</div>
<div class="section" id="simple-model-1-modelling-the-self-reported-health-as-a-function-of-the-deprivation-index">
<h2>Simple model 1: modelling the Self-reported Health as a function of the Deprivation Index<a class="headerlink" href="#simple-model-1-modelling-the-self-reported-health-as-a-function-of-the-deprivation-index" title="Permalink to this headline">¶</a></h2>
<p>The model is:
$<span class="math notranslate nohighlight">\( logit(p(x)) = intercept + \beta_1*deprindex \)</span>$</p>
<p>We now remind ourselves of our data and the behaviour of <code class="docutils literal notranslate"><span class="pre">DeprIndex</span></code> for our two <code class="docutils literal notranslate"><span class="pre">SRH</span></code> categories</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">g</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">FacetGrid</span><span class="p">(</span><span class="n">df_model</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="s2">&quot;SRH_binary&quot;</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">map_dataframe</span><span class="p">(</span><span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">,</span> <span class="s1">&#39;DeprIndex&#39;</span><span class="p">,</span><span class="n">discrete</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">set_axis_labels</span><span class="p">(</span><span class="s2">&quot;Deprivation Index&quot;</span><span class="p">,</span> <span class="s2">&quot;Count&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/4.3_Building_simple_model_18_0.png" src="../../_images/4.3_Building_simple_model_18_0.png" />
</div>
</div>
<p>Notice that the mode is zero in both cases, but there is a much higher proportion of <code class="docutils literal notranslate"><span class="pre">DeprIndex</span></code> scores in [3-6] when SRH = 0 compared to when SRH = 1. From this we already know that as <code class="docutils literal notranslate"><span class="pre">DeprIndex</span></code> decreases we may expect that the odds of SRH_binary=1 will <em>increase</em>.</p>
<p>Let’s now fit our model to the data using <code class="docutils literal notranslate"><span class="pre">statsmodels</span></code> library.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">df_model</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="s1">&#39;DeprIndex&#39;</span><span class="p">]</span>

<span class="c1"># Intercept is not added by default in Statsmodels, we need to add a constant (and array of 1s) for intercept</span>
<span class="n">X_atr</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> 
<span class="c1">#Create model instance</span>
<span class="n">logit_model</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Logit</span><span class="p">(</span><span class="n">df_model</span><span class="o">.</span><span class="n">SRH_binary</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">X_atr</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">logit_model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span> <span class="c1">#Fit model</span>

<span class="c1"># extract coefficient and intercept.</span>
<span class="n">intercept</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">coef1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Optimization terminated successfully.
         Current function value: 0.325395
         Iterations 6
</pre></div>
</div>
</div>
</div>
<p>Now we have fitted our model let us explore it so we understand what the model thinks is going on in the data.</p>
<p>Interpreting the model is the first step in model evaluation. In <em>Section 4.3</em> we will assess model performance in more detail.</p>
<div class="important admonition">
<p class="admonition-title">Ignorant Models</p>
<p>First, remember that models are ignorant. They only know about the information we have given them. In our case this means that the model does not know that <code class="docutils literal notranslate"><span class="pre">DeprIndex</span></code> is an ordinal value, rather it thinks it is continuous. This means that <em>according to the model’s universe</em> values less than zero are allowed in <code class="docutils literal notranslate"><span class="pre">DeprIndex</span></code>, as well as values greater than 6. Whether this is an issue or not depends on context and the conclusions one is drawing.</p>
</div>
<p>After the fit we have our intercept and coef, so we can predict the log-odds and p(x) using what we’ve learned above.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">df_model</span><span class="o">.</span><span class="n">DeprIndex</span><span class="o">.</span><span class="n">values</span><span class="p">))</span>
<span class="n">sigm</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">1</span><span class="o">/</span> <span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>


<span class="n">logodds</span> <span class="o">=</span> <span class="n">intercept</span> <span class="o">+</span> <span class="n">coef1</span><span class="o">*</span><span class="n">x</span>
<span class="n">odds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">logodds</span><span class="p">)</span>
<span class="n">probs</span> <span class="o">=</span> <span class="n">sigm</span><span class="p">(</span><span class="n">logodds</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">odds</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;odds&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">logodds</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;log(odds)&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">probs</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;p(x)&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">axes</span><span class="p">:</span> <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;DeprIndex&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/4.3_Building_simple_model_22_0.png" src="../../_images/4.3_Building_simple_model_22_0.png" />
</div>
</div>
<p>We can see from the odds that even with <code class="docutils literal notranslate"><span class="pre">DeprIndex</span></code> is 6 (highest deprivation) the variable SRH is around 2 times more likely to be 1 (good health) rather than 0. So, our model currently predicts <code class="docutils literal notranslate"><span class="pre">SRH_binary</span> <span class="pre">==</span> <span class="pre">1</span></code> for <em>every single</em> output of <code class="docutils literal notranslate"><span class="pre">DeprIndex</span></code> in our dataset.</p>
<p>This seems like strange behaviour. We know there are zeroes in our dataset, so does predicting 100% good health mean that our model is bad?</p>
<p>Let’s compare this with the outputs calculated from our data:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">g</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">FacetGrid</span><span class="p">(</span><span class="n">df_model</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="s2">&quot;DeprIndex&quot;</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">map_dataframe</span><span class="p">(</span><span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">,</span> <span class="s1">&#39;SRH_binary&#39;</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">set_axis_labels</span><span class="p">(</span><span class="s2">&quot;SRH&quot;</span><span class="p">,</span> <span class="s2">&quot;Count&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

                        
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/4.3_Building_simple_model_25_0.png" src="../../_images/4.3_Building_simple_model_25_0.png" />
</div>
</div>
<p>From these figures we can basically estimate <span class="math notranslate nohighlight">\(p(x)\)</span> directly from the data for each category. If you have a set of {0,1}, the the proportion of ones is simply the mean. From this proportion we calculate the odds and log odds.</p>
<p>In the next set of plots we will superpose this real data on top of the model regression lines and examine how well the model is representing our data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_lo</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">pivot_table</span><span class="p">(</span><span class="n">df_model</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;DeprIndex&#39;</span><span class="p">],</span> <span class="n">values</span><span class="o">=</span><span class="s1">&#39;SRH_binary&#39;</span><span class="p">,</span> <span class="n">aggfunc</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

<span class="n">px</span><span class="o">=</span><span class="n">df_lo</span><span class="o">.</span><span class="n">SRH_binary</span><span class="o">.</span><span class="n">values</span>

<span class="n">x</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
<span class="n">x</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>


<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>

<span class="n">odds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">logodds</span><span class="p">)</span>
<span class="n">probs</span> <span class="o">=</span> <span class="n">sigm</span><span class="p">(</span><span class="n">logodds</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">odds</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Model&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">px</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">px</span><span class="p">),</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Real Data&#39;</span><span class="p">,</span> <span class="n">ms</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;odds&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">logodds</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Model&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">px</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">px</span><span class="p">)),</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Real Data&#39;</span><span class="p">,</span> <span class="n">ms</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;logodds&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">probs</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Model&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">px</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Real Data&#39;</span><span class="p">,</span><span class="n">ms</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;p(x)&#39;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">axes</span><span class="p">:</span> 
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;DeprIndex&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/4.3_Building_simple_model_27_0.png" src="../../_images/4.3_Building_simple_model_27_0.png" />
</div>
</div>
<p>We can see above that logistic model has learned the data pretty well, even though when we binarise the output it is clearly not predicting any poor health.</p>
<p>This is because the predicted binarisation is sort of a hack to get a single predicted classification. What the logistic regression really learns about pretty well is the ratio of responses. If we look at the proportions of good health to poor health in the panel plot below we can see that <em>even at the highest deprivation index</em> we have approximately double the amount of ‘good health’ to ‘poor health’. This is what the model has learned.</p>
<p>Let’s now examine the summary of our fit:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                           Logit Regression Results                           
==============================================================================
Dep. Variable:                      y   No. Observations:                 2004
Model:                          Logit   Df Residuals:                     2002
Method:                           MLE   Df Model:                            1
Date:                Tue, 23 Nov 2021   Pseudo R-squ.:                 0.06533
Time:                        15:30:48   Log-Likelihood:                -652.09
converged:                       True   LL-Null:                       -697.67
Covariance Type:            nonrobust   LLR p-value:                 1.324e-21
==============================================================================
                 coef    std err          z      P&gt;|z|      [0.025      0.975]
------------------------------------------------------------------------------
const          2.6232      0.102     25.808      0.000       2.424       2.822
DeprIndex     -0.3520      0.036     -9.815      0.000      -0.422      -0.282
==============================================================================
</pre></div>
</div>
</div>
</div>
<div class="admonition-interpreting-the-fit-output admonition">
<p class="admonition-title">Interpreting the Fit Output</p>
<p>The fitted coeffient <code class="docutils literal notranslate"><span class="pre">DeprIndex</span></code> reflects the change of log odds of each increment on our independent variable (since the model thinks our predictor is a continous variable). This corresponds to the slope in the middle figure above (<code class="docutils literal notranslate"><span class="pre">DeprIndex</span></code> vs <code class="docutils literal notranslate"><span class="pre">log(odds</span></code>). We can also get the value from the fitted intercept from the same figure - this is the log(odds) value for when our <code class="docutils literal notranslate"><span class="pre">SRH</span></code> dependent variable is zero.</p>
<p>These coefficients come with a Standard Error (<code class="docutils literal notranslate"><span class="pre">std</span> <span class="pre">err</span></code>), which is an estimate of the standard deviation of the coefficient, representing the amount of sampling variation is expected in the coefficient. A low std error compared the value of the coefficient signifies a high significance for your coefficient (i.e. taking into account the variability in the coefficient the magnitude is likely to be non-zero). The significance is also reflected by the <code class="docutils literal notranslate"><span class="pre">z</span></code> and <code class="docutils literal notranslate"><span class="pre">p-value</span></code> (P&gt;|z|) and means how likely the coefficient is measured through our model by chance. Finally, the [0.025 and 0.975] measurements of values of the coefficients within within two standard deviations.</p>
<p>A <code class="docutils literal notranslate"><span class="pre">p-value</span></code> is a useful indication of whether or not your measurement might be a product of chance. However, it does not tell you whether the differences between the null model and your model are large enough to have practical real-life implications. Or indeed, whether your null model was ever a realistic comparison in the first place. Tests of statistical difference are not a replacement for understanding your model’s universe, but they can be useful additional evidence if understood well.</p>
</div>
<p>Note that p(x) vs  <code class="docutils literal notranslate"><span class="pre">DeprIndex</span></code> on the right of our figures above looks nothing like our nice sigmoid curve. What’s happening here?</p>
<p>Remember that the model thinks <code class="docutils literal notranslate"><span class="pre">DeprIndex</span></code> is a continuous variable. If we predict <span class="math notranslate nohighlight">\(P(x)\)</span> along a much wider scale than our dataset we get a better idea of the probability curve.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span><span class="mi">25</span><span class="p">,</span><span class="mi">200</span><span class="p">)</span>
<span class="c1"># create a function that starts at p(x) instead of x.</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>

<span class="n">logodds</span> <span class="o">=</span> <span class="n">intercept</span> <span class="o">+</span> <span class="n">coef1</span><span class="o">*</span><span class="n">x</span>
<span class="n">odds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">logodds</span><span class="p">)</span>
<span class="n">probs</span> <span class="o">=</span> <span class="n">sigm</span><span class="p">(</span><span class="n">logodds</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">odds</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;odds&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">logodds</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;log(odds)&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">probs</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;p(x)&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">add_patch</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">Rectangle</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mf">.6</span><span class="p">),</span><span class="mi">6</span><span class="p">,</span><span class="mf">.4</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">))</span>
<span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">axes</span><span class="p">:</span> <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;DeprIndex&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>



<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The Decision Boundary is at: </span><span class="si">{</span><span class="o">-</span><span class="n">intercept</span> <span class="o">/</span><span class="n">coef1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/4.3_Building_simple_model_32_0.png" src="../../_images/4.3_Building_simple_model_32_0.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The Decision Boundary is at: 7.451527883036597
</pre></div>
</div>
</div>
</div>
<p>When two binary outcomes are equally likely, <span class="math notranslate nohighlight">\(odds=1, log(odds)=0, \text{and } p(x)=0.5\)</span>. We can use this knowledge to calculate the decision boundary, meaning the point along the <code class="docutils literal notranslate"><span class="pre">DeprIndex</span></code> scale where the regression model changes its prediction of which outcome is more likely:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
0 &amp;= intercept + \beta_1*deprindex \\
\\
\frac{-intercept}{\beta_1} &amp;= deprindex \\ 
\end{aligned}
\end{split}\]</div>
<p>In the current model this is around 7.5.</p>
</div>
</div>
<div class="section" id="simple-model-2-modelling-srh-as-a-function-of-deprivation-and-age">
<h1>Simple model 2: modelling SRH as a function of deprivation and age<a class="headerlink" href="#simple-model-2-modelling-srh-as-a-function-of-deprivation-and-age" title="Permalink to this headline">¶</a></h1>
<p>Let’s now add a new predictor to our model, the age of the respondents. We expect for age to be one of the most relevant variables influencing how people experience health and be orthogonal to what our first variable of interest <code class="docutils literal notranslate"><span class="pre">DeprIndex</span></code> is actually measuring.</p>
<p>Let’s take a look a how our <code class="docutils literal notranslate"><span class="pre">SRH</span></code> variable behaves for different categories of age and deprivation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axes</span><span class="p">()</span>
<span class="n">df</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">pivot_table</span><span class="p">(</span><span class="n">df_model</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;DeprIndex&#39;</span><span class="p">],</span> <span class="n">values</span><span class="o">=</span><span class="s1">&#39;SRH_binary&#39;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;AgeCategory&#39;</span><span class="p">],</span> <span class="n">aggfunc</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;YlGnBu&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Fraction of responses of Good health for Deprivation and Age categories&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/4.3_Building_simple_model_35_0.png" src="../../_images/4.3_Building_simple_model_35_0.png" />
</div>
</div>
<p>In the figure above we observe some interesting variability across both variables. For example, older respondents in that are the least deprived are much less likely to report poor health than respondents of the same age group in highly deprived areas.</p>
<p>Our research question is interested on the socio-economical factors that can affect <code class="docutils literal notranslate"><span class="pre">SRH</span></code>. <code class="docutils literal notranslate"><span class="pre">Age</span></code> is not a socio economical factor, however, seeing the variability that it can have with both deprivation and self-reported health, it would be unwise to not take into account the age in our model.</p>
<p>In here, <code class="docutils literal notranslate"><span class="pre">Age</span></code> is basically is a confounding variable, which is a factor other than the one being studied that is associated both with the dependent variable (<code class="docutils literal notranslate"><span class="pre">SRH</span></code>) and with the factor being studied (<code class="docutils literal notranslate"><span class="pre">DeprIndex</span></code>). A confounding variable may distort or mask the effects of the <code class="docutils literal notranslate"><span class="pre">DeprIndex</span></code> on <code class="docutils literal notranslate"><span class="pre">SRH</span></code>.</p>
<p>Including <code class="docutils literal notranslate"><span class="pre">Age</span></code> in our model is essentially “controlling” for it. Remember that coefficients indicate the influece of a predictor on the dependent variable <em>assuming the other inputs are known</em>. Which in principle means that we compare different deprivation groups on fixed slices of age groups.</p>
<p>To make sure that are assumptions are right and that <code class="docutils literal notranslate"><span class="pre">Age</span></code> is an appropriate control variable, we look at the correlations between <code class="docutils literal notranslate"><span class="pre">Age</span></code>, <code class="docutils literal notranslate"><span class="pre">DeprIndex</span></code> and our binarised <code class="docutils literal notranslate"><span class="pre">SRH</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_model</span><span class="p">[[</span><span class="s1">&#39;DeprIndex&#39;</span><span class="p">,</span><span class="s1">&#39;SRH_binary&#39;</span><span class="p">,</span><span class="s1">&#39;AgeCategory&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;spearman&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>DeprIndex</th>
      <th>SRH_binary</th>
      <th>AgeCategory</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>DeprIndex</th>
      <td>1.000000</td>
      <td>-0.214105</td>
      <td>-0.177473</td>
    </tr>
    <tr>
      <th>SRH_binary</th>
      <td>-0.214105</td>
      <td>1.000000</td>
      <td>-0.107239</td>
    </tr>
    <tr>
      <th>AgeCategory</th>
      <td>-0.177473</td>
      <td>-0.107239</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>As we already know, <code class="docutils literal notranslate"><span class="pre">DeprIndex</span></code> has inverse relationship with the self-reported health. This relationship is slightly stronger than the relationship with of <code class="docutils literal notranslate"><span class="pre">SRH</span></code> and <code class="docutils literal notranslate"><span class="pre">Age</span></code>.</p>
<p>When we control for variables that have a positive correlation with both the independent and the dependent variable, the original relationship will be pushed down, and become more negative. The same is true if we control for a variable that has a negative correlation with both independent and dependent. It is thus likely that the relationship between <code class="docutils literal notranslate"><span class="pre">DeprIndex</span></code> and <code class="docutils literal notranslate"><span class="pre">SRH</span></code> will become stronger under control for <code class="docutils literal notranslate"><span class="pre">Age</span></code>.</p>
<p>Let’s fit the model and see,</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">df_model</span><span class="p">[[</span><span class="s1">&#39;AgeCategory&#39;</span><span class="p">,</span><span class="s1">&#39;DeprIndex&#39;</span><span class="p">]]</span>
<span class="n">X_Age_Dep</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="c1">#add constant for intercept</span>
<span class="n">logit_model2</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Logit</span><span class="p">(</span><span class="n">df_model</span><span class="o">.</span><span class="n">SRH_binary</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">X_Age_Dep</span><span class="p">)</span> <span class="c1">#Create model instance</span>
<span class="n">result2</span> <span class="o">=</span> <span class="n">logit_model2</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span> <span class="c1">#Fit model</span>

<span class="n">px</span> <span class="o">=</span> <span class="n">result2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_Age_Dep</span><span class="p">)</span>

<span class="nb">print</span> <span class="p">(</span><span class="n">result2</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Optimization terminated successfully.
         Current function value: 0.314769
         Iterations 7
                           Logit Regression Results                           
==============================================================================
Dep. Variable:                      y   No. Observations:                 2004
Model:                          Logit   Df Residuals:                     2001
Method:                           MLE   Df Model:                            2
Date:                Tue, 23 Nov 2021   Pseudo R-squ.:                 0.09585
Time:                        15:30:48   Log-Likelihood:                -630.80
converged:                       True   LL-Null:                       -697.67
Covariance Type:            nonrobust   LLR p-value:                 9.048e-30
===============================================================================
                  coef    std err          z      P&gt;|z|      [0.025      0.975]
-------------------------------------------------------------------------------
const           4.2763      0.301     14.230      0.000       3.687       4.865
AgeCategory    -0.4296      0.069     -6.198      0.000      -0.565      -0.294
DeprIndex      -0.3952      0.037    -10.646      0.000      -0.468      -0.322
===============================================================================
</pre></div>
</div>
</div>
</div>
<p>Indeed, the coefficient for <code class="docutils literal notranslate"><span class="pre">DeprIndex</span></code> is more negative now that we have isolated its effects from those of <code class="docutils literal notranslate"><span class="pre">Age</span></code> on <code class="docutils literal notranslate"><span class="pre">SRH</span></code>.</p>
<p>Now, let’s replicate the steps we showed before to see how well the model is representing our data. The next figure shows the expected probability of reporting good health for the different deprivation and age categories.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axes</span><span class="p">()</span>
<span class="n">dfm2</span> <span class="o">=</span> <span class="n">df_model</span><span class="p">[[</span><span class="s1">&#39;AgeCategory&#39;</span><span class="p">,</span><span class="s1">&#39;DeprIndex&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">dfm2</span><span class="p">[</span><span class="s1">&#39;px&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">px</span>
<span class="n">dfm2</span><span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">pivot_table</span><span class="p">(</span><span class="n">dfm2</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;DeprIndex&#39;</span><span class="p">],</span> <span class="n">values</span><span class="o">=</span><span class="s1">&#39;px&#39;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;AgeCategory&#39;</span><span class="p">],</span> <span class="n">aggfunc</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">dfm2</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;YlGnBu&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Probability of reporting Good health for Deprivation and Age categories&#39;</span><span class="p">)</span>

<span class="c1"># Decision boundary</span>
<span class="c1"># Tips here: https://scipython.com/blog/plotting-the-decision-boundary-of-a-logistic-regression-model/</span>
<span class="n">ages</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="n">intc</span><span class="p">,</span> <span class="n">b_age</span><span class="p">,</span> <span class="n">b_depr</span> <span class="o">=</span> <span class="n">result2</span><span class="o">.</span><span class="n">params</span>
<span class="n">c</span> <span class="o">=</span> <span class="o">-</span><span class="n">intc</span><span class="o">/</span><span class="n">b_depr</span>
<span class="n">m</span> <span class="o">=</span> <span class="o">-</span><span class="n">b_age</span><span class="o">/</span><span class="n">b_depr</span>
<span class="n">depr_boundary</span> <span class="o">=</span> <span class="n">m</span><span class="o">*</span><span class="n">ages</span> <span class="o">+</span> <span class="n">c</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ages</span><span class="p">,</span> <span class="n">depr_boundary</span><span class="p">,</span> <span class="s1">&#39;r--&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/4.3_Building_simple_model_42_0.png" src="../../_images/4.3_Building_simple_model_42_0.png" />
</div>
</div>
<p>The figure above shows a roughly similar pattern to the one from the data a couple of cells above, showing that the model is learning the pattern from the ratio of responses as both  <code class="docutils literal notranslate"><span class="pre">DeprIndex</span></code> and <code class="docutils literal notranslate"><span class="pre">Age</span></code> increases. The decision boundary is plotted as a red dashed line.</p>
<p>Again, we should remember that the model thinks <code class="docutils literal notranslate"><span class="pre">DeprIndex</span></code> and <code class="docutils literal notranslate"><span class="pre">AgeCategory</span></code> are continuous variables. If we predict  <span class="math notranslate nohighlight">\(𝑃(𝑥)\)</span>  along a much wider scale than our dataset we get a better idea of the two-dimensional probability curve.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">matplotlib.patches</span> <span class="kn">import</span> <span class="n">Rectangle</span>

<span class="n">ages</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span><span class="mi">20</span><span class="p">)</span>
<span class="n">depr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span><span class="mi">20</span><span class="p">)</span>

<span class="n">X</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">ages</span><span class="p">,</span><span class="n">depr</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
<span class="n">X_Age_Dep</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="c1">#add constant for intercept</span>

<span class="n">px</span><span class="o">=</span><span class="n">result2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_Age_Dep</span><span class="p">)</span>

<span class="n">temp_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;AgeCategory&#39;</span><span class="p">,</span><span class="s1">&#39;DeprIndex&#39;</span><span class="p">])</span>
<span class="n">temp_df</span><span class="p">[</span><span class="s1">&#39;px&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">px</span>


<span class="n">dfsyn</span><span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">pivot_table</span><span class="p">(</span><span class="n">temp_df</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;DeprIndex&#39;</span><span class="p">],</span> <span class="n">values</span><span class="o">=</span><span class="s1">&#39;px&#39;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;AgeCategory&#39;</span><span class="p">],</span> <span class="n">aggfunc</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="c1">#print(dfsyn)</span>

<span class="c1"># rectangle for original data</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">dfsyn</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;YlGnBu&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">add_patch</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">Rectangle</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span><span class="mi">11</span><span class="p">),</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">))</span>

<span class="c1"># Decision boundary</span>
<span class="c1"># Tips here: https://scipython.com/blog/plotting-the-decision-boundary-of-a-logistic-regression-model/</span>
<span class="n">intc</span><span class="p">,</span> <span class="n">b_age</span><span class="p">,</span> <span class="n">b_depr</span> <span class="o">=</span> <span class="n">result2</span><span class="o">.</span><span class="n">params</span>
<span class="n">c</span> <span class="o">=</span> <span class="o">-</span><span class="n">intc</span><span class="o">/</span><span class="n">b_depr</span>
<span class="n">m</span> <span class="o">=</span> <span class="o">-</span><span class="n">b_age</span><span class="o">/</span><span class="n">b_depr</span>
<span class="n">depr_boundary</span> <span class="o">=</span> <span class="n">m</span><span class="o">*</span><span class="n">ages</span> <span class="o">+</span> <span class="n">c</span>
<span class="c1"># not sure why but heatmap coordinate system starts with 0,0, adjust so (0,0) on our scale is (10,10)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ages</span><span class="o">+</span><span class="mi">10</span><span class="p">,</span> <span class="n">depr_boundary</span><span class="o">+</span><span class="mi">10</span><span class="p">,</span> <span class="s1">&#39;r--&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/4.3_Building_simple_model_44_0.png" src="../../_images/4.3_Building_simple_model_44_0.png" />
</div>
</div>
<p>Our data space lives in the sub-space inside the white rectangle.</p>
<p>The red dashed line is the decision boundary at <span class="math notranslate nohighlight">\(p(x)=0.5\)</span>.</p>
<p>Imagine that the change in colour represents a change in ground height, with blue being high and cream beind low. If we extract the probability from the diagonal of our matrix we recover our nice sigmoid function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dfsyn</span><span class="p">)</span><span class="o">.</span><span class="n">diagonal</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)),</span><span class="n">x</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;p(x)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/4.3_Building_simple_model_46_0.png" src="../../_images/4.3_Building_simple_model_46_0.png" />
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "alan-turing-institute/rds-course",
            ref: "develop",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./modules/m4"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="4.2_Fitting_Models.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">4.2 Fitting (Regression) Models</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="4.4_Evaluating_a_model.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">4.4 Evaluating models</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Research Engineering Group, The Alan Turing Institute<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>