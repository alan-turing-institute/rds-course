
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>4.1 The What and Why of Statistical Modelling &#8212; Research Data Science</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe,.cell"
        const thebe_selector_input = "pre,.cell_input div.highlight"
        const thebe_selector_output = ".output,.cell_output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="4.2 Fitting (Regression) Models" href="4.2_Fitting_Models.html" />
    <link rel="prev" title="Overview" href="overview.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Research Data Science</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../index.html">
   Welcome to The Alan Turing Institute’s Introduction to Research Data Science course
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Module 1: Introduction to Data Science
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../m1/overview.html">
   Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../m1/1.1-WhatIsDataScience.html">
   1.1 What is (research) data science?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../m1/1.2-DataScienceProjectLifecycle.html">
   1.2 Research Data Science project lifecycle
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../m1/1.3-EDIForDataScience.html">
   1.3 Equality, diversity and inclusion in data science
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../m1/1.4-CollaborationAndReproducibility.html">
   1.4 Collaboration and reproducibility
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../m1/hands-on.html">
   Module 1: Hands-on session
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Module 2: Handling data
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../m2/2-overview.html">
   Overview
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../m2/2-01-GettingLoading.html">
   2.1 Getting and Loading Data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../m2/2-01-01-WhereToFindData.html">
     2.1.1 Where to find data?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../m2/2-01-02-LegalityAndEthics.html">
     2.1.2 Legality and Ethics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../m2/2-01-03-PandasIntro.html">
     2.1.3 Pandas intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../m2/2-01-04-DataSourcesAndFormats.html">
     2.1.4 Data Sources and Formats
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../m2/2-01-05-ControllingAccess.html">
     2.1.5 Controlling access
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../m2/2-02-ExploringWrangling.html">
   2.2 Exploring and Wrangling Data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../m2/2-02-01-DataConsistency.html">
     2.2.1 Data Consistency
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../m2/2-02-02-ModifyingColumnsAndIndices.html">
     2.2.2 Modifying Columns and Indices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../m2/2-02-03-FeatureEngineering.html">
     2.2.3 Feature Engineering
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../m2/2-02-04-DataManipulation.html">
     2.2.4 Data Manipulation
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../m2/2-02-04-01-TimeAndDateData.html">
       2.2.4.1 Time and Date Data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../m2/2-02-04-02-TextData.html">
       2.2.4.2 Text data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../m2/2-02-04-03-CategoricalData.html">
       2.2.4.3 Categorical Data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../m2/2-02-04-04-ImageData.html">
       2.2.4.4 Image Data
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../m2/2-02-05-PrivacyAndAnonymisation.html">
     2.2.5 Privacy and Anonymisation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../m2/2-02-06-LinkingDatasets.html">
     2.2.6 Linking Datasets
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../m2/2-02-07-MissingData.html">
     2.2.7 Missing Data
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../m2/2-hands-on.html">
   Module 2: Hands-on session
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../m2/2-hands-on-complete.html">
   Module 2: Hands-on session (Solutions)
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Module 3: Data Visualisation &amp; Exploration
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../m3/overview.html">
   Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../m3/3.1-FiguresGoneWrong.html">
   3.1 Figures gone wrong
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../m3/3.2-RulesOfTheGame.html">
   3.2 Rules of the data visualisation game
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../m3/3.3-Atlas0fVisualisations.html">
   3.3 Atlas of Visualisations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../m3/3.4-StoryTelling.html">
   3.4 Storytelling with data visualisation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../m3/3.5-DataVisForExploration.html">
   3.5 Walkthrough: visualisation for data exploration
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../m3/hands-on.html">
   Module 3 hands-on session
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Module 4: Introduction to Modelling
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="overview.html">
   Overview
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   4.1 The What and Why of Statistical Modelling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="4.2_Fitting_Models.html">
   4.2 Fitting (Regression) Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="4.3_Building_simple_model.html">
   4.3 Building a simple model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="4.4_Evaluating_a_model.html">
   4.4 Evaluating models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="hands-on.html">
   Module 4 hands-on session
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/modules/m4/4.1_What_and_Why.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/alan-turing-institute/rds-course"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/alan-turing-institute/rds-course/issues/new?title=Issue%20on%20page%20%2Fmodules/m4/4.1_What_and_Why.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/alan-turing-institute/rds-course/develop?urlpath=tree/coursebook/modules/m4/4.1_What_and_Why.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <button type="button" class="btn btn-secondary topbarbtn"
            onclick="initThebeSBT()" title="Launch Thebe" data-toggle="tooltip" data-placement="left"><i
                class="fas fa-play"></i><span style="margin-left: .4em;">Live Code</span></button>
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-is-data">
   What is data?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-is-probability">
   What is Probability?
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#conditional-probability">
     Conditional Probability
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#parameters-and-distributions">
   Parameters and Distributions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sampling-bias-and-the-central-limit-theorem">
   Sampling bias and the Central Limit Theorem
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#statistical-learning">
   Statistical Learning
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#references-and-further-reading">
     References and Further Reading
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="the-what-and-why-of-statistical-modelling">
<span id="section4-1"></span><h1>4.1 The What and Why of Statistical Modelling<a class="headerlink" href="#the-what-and-why-of-statistical-modelling" title="Permalink to this headline">¶</a></h1>
<p>Models are used in all walks of life to facilitate learning. A product designer may build a mock-up of the intended product to learn how the real-life counterpart may work. Similarly, architects use blueprints to learn and communicate something about a building.</p>
<p>These models are abstractions of the real world that capture key characteristics of the thing they imitate.</p>
<p>No model is perfect because the real world is endlessly complex. Rather, models are approximations of some phenonemon. Models are useful when they allow us to learn something about the subject.</p>
<p><em>Statistical</em> modelling is conceptually similar. Simply put, a statistical model is a mathematical abstraction.</p>
<p>In theory, models are infinitely flexible. However, there are many trade-offs, for example between complexity and interpretability, that we will cover in this module. The flexibility of models means that it is important to ask <em>why</em> you are modelling before embarking on a modelling problem. Broadly, modelling efforts are of two types (see below box).</p>
<div class="important admonition">
<p class="admonition-title">Reasons for Modelling</p>
<p><strong>Modelling for Prediction</strong>. The model’s performance is more important than understanding the mechanism of data generation. Here, robust prediction of an outcome or reliable discrimination between different types of data is more important than explaining the underlying phenomenon. These data science tasks crop up often in industry, for example it may be more important to accurately predict movie preferences from a set of input variables than understand <em>how</em> your input variables translate to movie preferences.</p>
<p><strong>Modelling for Explanation</strong>. A premium is placed on understanding the mechanism of data generation. We don’t want a highly complex model that achieves excellent performance yet does not allow us to better understand the underlying phenomenon. When model interpretability is important there is a trade-off between model complexity and scientific value.</p>
</div>
<p>In this course we will focus on <strong>modelling for explanation</strong>, since this type of modelling in more common in scientific research. We do not pretend to be a module that covers the wide variety of machine learning techniques available to apply to your data science problem.</p>
<p>From now on when we are using the term <em>models</em> what we are <em>actually</em> referring to <em>statistical models</em>.</p>
<p>The statistical models we are concerned with attempt to capture key characteristics of <strong>data generating processes</strong> so that we can learn about the associated <strong>phenomenon</strong>.</p>
<p>To understand these models first we need to think about data for a moment.</p>
<div class="section" id="what-is-data">
<h2>What is data?<a class="headerlink" href="#what-is-data" title="Permalink to this headline">¶</a></h2>
<p>Data is a messy peek into an underlying phenomenon. What we really want to learn about is a <strong>phenomenon</strong>, for example what contributes to good health. However, the real-world is complicated and phenomena are never known precisely. Many natural phenomena have intrinsic variability, or <em>randomness</em>. For example, human bodies are massively variable between individuals, so it is reasonable to expect that their health, and also the myriad factors that contribute to it, will be different.</p>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<div class="note dropdown admonition">
<p class="admonition-title">Randomness</p>
<p>Even when a process is deterministic (i.e. the same start state produce the same end state each time) it can be complicated enough so that it useful to model it as a random process. In fact, there are very few things that are truly random, we just don’t know the models in enough detail. Remember that models are <em>useful approximations</em> of the real world.</p>
</div>
</div>
<p>Phenomena are only ever accessed through a process of <strong>measurement</strong>. Measurement brings two barriers to the underlying phenomena.</p>
<ul class="simple">
<li><p><strong>Sampling Bias</strong>. We can never observe the whole population. This means that we only ever <em>sample</em> some of the distribution. The sample will fail to capture all the characteristics of the population. For example, an alien that picks a couple of individuals from the human timeline might choose a couple of vikings and therefore conclude that all humans have beards. This is called <strong>sampling bias</strong>.</p></li>
<li><p><strong>Measurement Error</strong>. The measuring device <em>itself</em> could be inaccurate or imprecise. In our example the measuring device is self-reporting, which may have its own variability - the same person may respond differently on different days, and some people may be over or under confident.</p></li>
</ul>
<p>Measurement, or observation, provides a set of data. Data are <em>related</em> to the underlying phenomenon, but have been contorted by sampling bias (intrinsic variability will mean that each sample will be different) and measurement uncertainty.</p>
<p>Together, the phenomenon and method of observation make up the <strong>data generating process</strong>.</p>
<p>Mapping out the data generating process over the space of all possible events gives rise to what we call a <strong>distribution</strong> (more on this later). Understanding how a data generating process is distributed across members of the population of interest is a key goal of statistical modeling.</p>
<div class="figure align-default" id="modelprocess">
<a class="reference internal image-reference" href="../../_images/4.1_1.svg"><img alt="../../_images/4.1_1.svg" src="../../_images/4.1_1.svg" width="800px" /></a>
</div>
</div>
<div class="section" id="what-is-probability">
<h2>What is Probability?<a class="headerlink" href="#what-is-probability" title="Permalink to this headline">¶</a></h2>
<p>In the previous section we talked about variability in a phenomenon producing different observations each time. We can think about variability in terms of <em>uncertainty</em>. If a process is highly variable then we will be less certain of the exact value it produces each time.</p>
<p><strong>Probability</strong> is a branch of mathematics that allows us to reason about uncertainty.</p>
<p>Probability formalises guessing. Let us consider trying to guess the ice cream flavour that customers pick. There are two flavours: <code class="docutils literal notranslate"><span class="pre">chocolate</span></code>, <code class="docutils literal notranslate"><span class="pre">strawberry</span></code>. We can reason about how likely each flavour is to be chosen, <span class="math notranslate nohighlight">\(P(x)\)</span> by adopting two golden rules.</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P(x) \geq 0\)</span>. That is, the least probable you can get is zero chance of an event ever happening.</p></li>
<li><p><span class="math notranslate nohighlight">\(\sum^{N}_{i=1} P(x_i) = 1\)</span>. That is, all the probabilities should add up to 1. This means that if one event, <span class="math notranslate nohighlight">\(x\)</span>, happens all the time, <span class="math notranslate nohighlight">\(P(x)=1\)</span>.</p></li>
</ul>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>There are two ways of thinking about what <span class="math notranslate nohighlight">\(P(x)\)</span> means.</p>
<ul class="simple">
<li><p>We can treat <span class="math notranslate nohighlight">\(P(x)\)</span> as a <strong>frequency</strong>. If <span class="math notranslate nohighlight">\(P(chocolate) = .7\)</span> means that if we were to serve millions of customers they would choose chocolate 70% of the time.</p></li>
<li><p>We can treat <span class="math notranslate nohighlight">\(P(x)\)</span> as a <strong>belief</strong>. In this framework <span class="math notranslate nohighlight">\(P(chocolate)\)</span> indicates our degree of confidence that someone will choose chocolate.</p></li>
</ul>
<p>The first type of probabilistic framework is called <strong>Frequentist</strong> Probability. The second is called the <strong>Bayesian</strong> approach. These two frameworks support different types of inferences. Most of the modelling concepts covered in this module appear in both frameworks.</p>
</div>
<div class="section" id="conditional-probability">
<h3>Conditional Probability<a class="headerlink" href="#conditional-probability" title="Permalink to this headline">¶</a></h3>
<p>In most cases when we think about probability of some events happening we assume that other events that have <em>already happened</em>. In our ice cream example we do not concern ourselves with the probability that there is a shop selling ice cream, or the probability that a customer would walk in to it. We assume that these have already happened and then make sure the <em>event space</em> we are interested in sums to one so that we can reason about the uncertainty.</p>
<p>This is called <strong>Conditional Probability</strong>. <span class="math notranslate nohighlight">\(P(x)\)</span> is the probability of <span class="math notranslate nohighlight">\(x\)</span> happening within a bounded event space, conditioned on some stuff that is assumed to have happened. Let <span class="math notranslate nohighlight">\(y\)</span> be the probability that a customer walks into an ice cream shop, and <span class="math notranslate nohighlight">\(x\)</span> be the probability that someone chooses chocolate. The conditional probability formula is given by:</p>
<div class="math notranslate nohighlight">
\[P(x|y) = \frac{P(x \cap y)}{P(y)}\]</div>
<p>The left hand side, <span class="math notranslate nohighlight">\(P(x|y)\)</span>, is often read “Probability of <span class="math notranslate nohighlight">\(x\)</span> given <span class="math notranslate nohighlight">\(y\)</span>”. The right hand side consists of the <em>intersection</em> of <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span>, <span class="math notranslate nohighlight">\(P(x \cap y)\)</span>, which is all events of <em>both</em> <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span>. This is also called the <em>joint probability</em>.</p>
<p>Conditional probability essentially normalises the event space within the mini universe under consideration, as visualised in <a class="reference external" href="https://setosa.io/conditional/">this beautiful animation by Victor Powell</a>.</p>
<div class="admonition-conditional-probability admonition">
<p class="admonition-title">Conditional Probability</p>
<p>Conditional probability is everywhere in modelling. In particular there are two important conditional probabilities:</p>
<ul class="simple">
<li><p>The probability of the data, given the parameters of the distribution: <span class="math notranslate nohighlight">\(P(x | \theta)\)</span>. This is called the <strong>likelihood</strong>. Models are often fitted by assuming some starting values for the parameters, seeing how likely the data is under those parameters, then trying to find the parameters that give highest likelihood. This is called <strong>Maximum Likelihood Estimation</strong> (more on this in <a class="reference internal" href="4.2_Fitting_Models.html#section4-2"><span class="std std-ref"><em>Section 4.2</em></span></a>.</p></li>
<li><p>The probability of the parameters, given the data: <span class="math notranslate nohighlight">\(P(\theta | x)\)</span>. Modelling boils down to inferring the parameter values that are most consistent for a given set of data. <span class="math notranslate nohighlight">\(P(\theta | x)\)</span> is often called the <em>posterior</em>.</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="parameters-and-distributions">
<h2>Parameters and Distributions<a class="headerlink" href="#parameters-and-distributions" title="Permalink to this headline">¶</a></h2>
<p>A <em>distribution</em> is how the probability of a variable is spread across the event space. Distributions are used as useful approximations of data generating processes.</p>
<p>In our simple example <span class="math notranslate nohighlight">\(x = chocolate\)</span> and <span class="math notranslate nohighlight">\(P(x) = 0.7\)</span>. So, <span class="math notranslate nohighlight">\(P(not x) = 0.3\)</span>. There are two events in the probability space, they are both assigned a non-zero probability that adds up to one. We can therefore capture the entire distribution with the probability vector <span class="math notranslate nohighlight">\([x, notx]=[0.7,0.3]\)</span>.</p>
<p>Observe that with this particular distribution we can control the distribution by changing <span class="math notranslate nohighlight">\(P(x)\)</span>, since <span class="math notranslate nohighlight">\(P(notx)=1-P(x)\)</span>. If we change <span class="math notranslate nohighlight">\(P(x)\)</span> to 0.2, we expect the number of customers choosing chocolate to decrease, and the number of customers not choosing chocolate to increase, meaning that the probability vector will be <span class="math notranslate nohighlight">\([0.2,0.8]\)</span>.</p>
<p>So, we can specify the entire distribution by changing one value, <span class="math notranslate nohighlight">\(P(x)\)</span>. This is an example of a <em>parameterised distribution</em>. Parameters govern probability distributions. A parameter is a mathematical value that, if altered, changes the expected behaviour of a process.</p>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<div class="admonition-p-x-and-p-x admonition">
<p class="admonition-title"><span class="math notranslate nohighlight">\(P(x)\)</span> and <span class="math notranslate nohighlight">\(P(x)\)</span></p>
<p>The bernoulli distribution is something of a special case, where <span class="math notranslate nohighlight">\(P(x)\)</span> can have multiple meanings. It is the probability of <span class="math notranslate nohighlight">\(x\)</span> happening, the mean of the output distribution, <em>and</em> the single parameter of the distribution.</p>
</div>
</div>
<p><span class="math notranslate nohighlight">\(P(x)\)</span> is the key parameter in the <strong>Bernoulli</strong> distribution, which is the distribution of a <strong>random variable</strong> that can only take two values, <span class="math notranslate nohighlight">\(\{0,1\}\)</span>, with the <span class="math notranslate nohighlight">\(1\)</span> signifying the presence of <span class="math notranslate nohighlight">\(x\)</span>. We can <strong>sample</strong> individual observations from this distribution to give us a set of data.</p>
<p>In our example chocoloate choosers with appear as <span class="math notranslate nohighlight">\(1\)</span>s, and strawberry choosers as <span class="math notranslate nohighlight">\(0\)</span>s. If we sample 15 customers from a bernoulli distribution with <span class="math notranslate nohighlight">\(P(x)=0.7\)</span> we get a string of customers that choose mostly chocolate, but also a few strawberry choosers.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">bernoulli</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">bernoulli</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">.7</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">bernoulli</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">.7</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="mi">100000</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0 1 1 0 1 1 1 0 1 1 1 0 1 1 0]
0.70277
</pre></div>
</div>
</div>
</div>
<p>With a big enough sample the amount of people choosing chocolate will always rest at our chosen parameter.</p>
<p>For different values of <span class="math notranslate nohighlight">\(P(chocolate)\)</span>, the below plot shows some simulations of the proportion of customers choosing chocolate as the number of customers increase.</p>
<p>With the bernoulli distribution that proportion can be directly computed by calculating the mean.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">bernoulli</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">200</span><span class="p">)</span>
<span class="n">pchoc</span> <span class="o">=</span> <span class="p">[</span><span class="mf">.2</span><span class="p">,</span> <span class="mf">.4</span><span class="p">,</span> <span class="mf">.6</span><span class="p">]</span>
<span class="n">sample_sizes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>


<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pchoc</span><span class="p">),</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">for</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">pchoc</span><span class="p">):</span>
    <span class="n">props</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">bernoulli</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">s</span><span class="p">))</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">sample_sizes</span><span class="p">]</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sample_sizes</span><span class="p">,</span> <span class="n">props</span><span class="p">,</span> <span class="s1">&#39;o--&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Number of Customers&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">axes</span><span class="p">:</span> <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;P(Chocolate)&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/4.1_What_and_Why_6_0.png" src="../../_images/4.1_What_and_Why_6_0.png" />
</div>
</div>
</div>
<div class="section" id="sampling-bias-and-the-central-limit-theorem">
<h2>Sampling bias and the Central Limit Theorem<a class="headerlink" href="#sampling-bias-and-the-central-limit-theorem" title="Permalink to this headline">¶</a></h2>
<p>Notice two things in the above plots:</p>
<ul class="simple">
<li><p>At lower sample numbers the sample mean varies more widely. This is <strong>sampling bias</strong>. Any parameter you calculate from data will vary from sample to sample. The sample-to-sample variability of a parameter is its <strong>sampling distribution</strong>.</p></li>
<li><p>Even at larger samples the sample mean varies around the true probability (which is never known in practice).</p></li>
</ul>
<p>As statisticians we know the nature of this variation. There is a rather remarkable statistical property of sampling called the <strong>Central Limit Theorem</strong>, which states when sample sizes are large enough the <em>sampling distribution of the mean</em> will be normally distributed (a bell curve). Crucially this holds even if the data is not normally distributed (as in our case).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">p</span><span class="o">=</span><span class="mf">.5</span>
<span class="n">sample_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">]</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="mi">10000</span>


<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">sample_sizes</span><span class="p">),</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>

<span class="k">for</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">s</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sample_sizes</span><span class="p">):</span>
    <span class="n">sampling_dist</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">bernoulli</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">s</span><span class="p">))</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)]</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">sampling_dist</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Sample Size=</span><span class="si">{</span><span class="n">s</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/4.1_What_and_Why_8_0.png" src="../../_images/4.1_What_and_Why_8_0.png" />
</div>
</div>
<p>The intuition behind the Central Limit Theorem is two fold:</p>
<ul class="simple">
<li><p>The more ways a thing can happen, the more likely it is to happen.</p></li>
<li><p>There are more ways of making the average than any other number.</p></li>
</ul>
<p>For example, take the leftmost plot. Here we have flipped a coin five times. There are 10 ways of getting 60% heads, and 10 ways of getting 40% heads, but only 1 way of getting all heads.</p>
<p>The numbers of ways something can happen is mathematically captured in probability:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.special</span> <span class="kn">import</span> <span class="n">binom</span> <span class="k">as</span> <span class="n">bcoeff</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">binom</span>

<span class="n">p</span> <span class="o">=</span> <span class="mf">.5</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">ways</span> <span class="o">=</span> <span class="p">[</span><span class="n">bcoeff</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">k</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
<span class="n">prob</span> <span class="o">=</span> <span class="p">[</span><span class="n">binom</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
<span class="n">noutcomes</span> <span class="o">=</span> <span class="p">[</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">noutcomes</span><span class="p">,</span><span class="n">ways</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Ways&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Count (y = 1)&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">noutcomes</span><span class="p">,</span><span class="n">prob</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Probability&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Count (y = 1)&#39;</span><span class="p">)</span>


<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/4.1_What_and_Why_10_0.png" src="../../_images/4.1_What_and_Why_10_0.png" />
</div>
</div>
</div>
<div class="section" id="statistical-learning">
<h2>Statistical Learning<a class="headerlink" href="#statistical-learning" title="Permalink to this headline">¶</a></h2>
<p>What we have been doing so far is generating data by sampling from a distribution with parameters. We have been using a <strong>generative model</strong>.</p>
<div class="admonition-generative-models admonition">
<p class="admonition-title">Generative Models</p>
<p>A generative model describes how a dataset is generated, in terms of probability distributions. By sampling from this model, we are able to generate new data. Parameters are the control dials on a generative model.</p>
</div>
<p>In most real situations, <strong>neither the generative model nor the parameters are known</strong>, and we will need to estimate them using the data we have collected. Statistical modeling works from the data upwards to figure out a model that might plausibly explain the data.</p>
<p>Once we have learned a suitable model for our data, we can make inferences about the underlying phenomena using our knowledge of statistical sampling. We can also make predictions about new data.</p>
<p>Collecting new data will allow us to test our predictions and revise our model, and the scientific cycle continues.</p>
<div class="figure align-default" id="id1">
<a class="reference internal image-reference" href="../../_images/4.1_2.svg"><img alt="../../_images/4.1_2.svg" src="../../_images/4.1_2.svg" width="600px" /></a>
</div>
<p>In this section we have learned the theoretical building blocks of modelling. In the next section we will peek inside a model and learn how a model represents data.</p>
<div class="section" id="references-and-further-reading">
<h3>References and Further Reading<a class="headerlink" href="#references-and-further-reading" title="Permalink to this headline">¶</a></h3>
<p><strong>Probability</strong></p>
<ul class="simple">
<li><p><a class="reference external" href="https://seeing-theory.brown.edu/basic-probability/index.html">Basic probability visualisations</a></p></li>
<li><p><a class="reference external" href="https://seeing-theory.brown.edu/basic-probability/index.html">Conditional Probability animation</a></p></li>
<li><p><a class="reference external" href="https://seeing-theory.brown.edu/basic-probability/index.html">Confidence Intervals Animation</a></p></li>
<li><p><a class="reference external" href="https://web.stanford.edu/group/poldracklab/statsthinking21/probability.html#what-do-probabilities-mean">Poldrack Statistical Thinking Probability Chapter</a></p></li>
</ul>
<p><strong>Modelling</strong>:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://betanalpha.github.io/assets/case_studies/modeling_and_inference.html#11_the_observational_process">Betancourt blog on Modelling and Inference</a></p></li>
<li><p><a class="reference external" href="https://web.stanford.edu/group/poldracklab/statsthinking21/fitting-models-to-data.html#what-is-a-model">Statistical Thinking Chapter ‘What is a model’</a></p></li>
<li><p><a class="reference external" href="https://web.stanford.edu/class/bios221/book/Chap-Generative.html">Modern Statistics for Modern Biology Chapter 1 - Generative Models for Discrete Data</a></p></li>
<li><p><a class="reference external" href="https://xcelab.net/rmpubs/sr2/statisticalrethinking2_chapters1and2.pdf">McElreath Statistical Rethinking Chapters 1 &amp; 2</a></p></li>
</ul>
<!-- WHAT IS A MODEL

Here refer to the hackmd and point out that we have been referring to generative models (i.e. known parameters, can generate data).

But really the parameters are not known.

We want to learn them from data. 

Use the diagrams in the hackmd. 

Here point out that we have been working with Generative Models. I.e. known parameters, --> </div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "alan-turing-institute/rds-course",
            ref: "develop",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./modules/m4"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="overview.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Overview</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="4.2_Fitting_Models.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">4.2 Fitting (Regression) Models</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Research Engineering Group, The Alan Turing Institute<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>