{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f36c6e2a",
   "metadata": {},
   "source": [
    "# 1.1 What is (research) data science?\n",
    "\n",
    "There is an incredible abundance of webpages, Youtube videos, newspaper articles and books defining what data science is. Instead of providing yet another clear-cut single definition of such a complex, multifaced and buzzwordy topic, we have decided to approach data science by discussing the main components of this profession and from there presenting what the role of a research data scientist is in particular. \n",
    "\n",
    "In this submodule we will offer an overview of:\n",
    "- what we mean when we say \"data\" in data science\n",
    "- the different types of tasks that a data scientist covers\n",
    "- what role data science plays in research\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6687a7c8",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "- Data is central to data science\n",
    "- Data is not a natural resource\n",
    "\n",
    "![data_oil](../../figures/m1/data_oil.jpeg)\n",
    "\n",
    "<details>\n",
    "\n",
    "We start from the most essential element of this profession, data. The prompt availability of large-scale datasets for training face recognition algorithms or language models is not something that we should take for granted, and it is absolutely not something that has always been in place. Concepts such as \"Data mining\" and \"Data is the new oil\" depict data as something crude, non-human, like a natural, primitive and unrefined resource and hide the enormous amount of labour, resources, infrastructure, and time that has taken to make such data available. While we will expand further around such concepts in lesson 1.3, we highlight already here a few central points that are essential in our course.\n",
    "\n",
    "</details>\n",
    "\n",
    "### Scarcity & Abundance\n",
    "\n",
    "- The availability of data is a fairly new phenomenon\n",
    "- Acquiring data remains very complex\n",
    "\n",
    "![digitisation](../../figures/m1/digitisation.jpeg)\n",
    "[Image link](https://www.bl.uk/help/initiate-a-new-digitisation-project-with-the-british-library)\n",
    "\n",
    "<details>\n",
    "\n",
    "The abundance of data, which has led to the advent of another very popular\n",
    "buzzword, \"big data\", is something our society has rapidly got accustomed to\n",
    "(due to its huge demand), but is a fairly new phenomenon. Let us consider a\n",
    "specific example from the field of speech recognition: In the Eighties a group\n",
    "of researchers at IBM research decided to develop a system that, instead of a\n",
    "top-down rules-based approach (a so-called knowledge system), would employ a\n",
    "statistical method focused on how often words appear in the same context.\n",
    "However, to train such a method, an enormous amount of text data would have been\n",
    "needed, particularly when compared to what was available back then. IBM researchers\n",
    "tried everything, from digitised technical manuals to children's books and\n",
    "patents. Now that data is everywhere and everything is seen as data we tend to\n",
    "forget how rapidly things have changed with the advent of the Internet first and\n",
    "the World Wide Web right after, together with continuous investments in data\n",
    "storage facilities. To get a quick idea, check websites like [Internet Live\n",
    "Stats](https://www.internetlivestats.com/) or explore the collection of an\n",
    "impossible to achieve project such as [The Internet\n",
    "Archive](https://archive.org/about/).\n",
    "\n",
    "</details>\n",
    "\n",
    "### Representativeness\n",
    "\n",
    "- Each dataset, no matter how large it is, remains a sample\n",
    "- The question we should ask ourselves is \"how well can this be representative of the phenomenon I want to study?\"\n",
    "\n",
    "![twitter](../../figures/m1/twitter.jpeg)\n",
    "[Image link](https://www.businessinsider.com/library-of-congress-twitter-wont-archive-every-public-tweet-anymore-2017-12?r=US&IR=T)\n",
    "\n",
    "<details>\n",
    "\n",
    "Together with data scarcity, the other aspect that we should never underestimate when we speak about data is whether they are representative of the phenomenon we aim to study. In a recent article by [Anna Rogers](https://aclanthology.org/2021.acl-long.170.pdf)<sup>[1](#References)</sup>, the author considers the following argument: “the size of the data is so large that, in fact, our training sets are not a sample at all, they are the entire data universe”. Rogers replies to it by saying that this argument would stand if the “data universe\" that we use for training for instance a speech recognition system was the same as “the totality of human speech/writing\". It is not, and will hopefully never be, because collecting all speech is problematic for ethical, legal, and practical reasons. Anything less than that is a sample. Given the existing social structures, no matter how big that sample is, it is not representative due to (at least) unequal access to technology, unequal possibility to defend one’s privacy and copyright, and limited access to the huge volumes of speech produced in the “walled garden\" platforms like Facebook. \n",
    "\n",
    "</details>\n",
    "\n",
    "### Creation\n",
    "\n",
    "- Data is <ins>always</ins> the product of human decisions and actions\n",
    "- It is the outcome of an enormous amount of labour, resources, infrastructure, and time\n",
    "\n",
    "![imagenet](../../figures/m1/imagenet.jpeg)\n",
    "[Image link](https://excavating.ai/)\n",
    "\n",
    "<details>\n",
    "Data is not a natural resource, but the product of human decisions. Whether we are conscious of it or not, there is always a human-in-the-loop when we speak about data creation. Data creation can be, for instance, collecting information or the tracking of historical information, organising information in specific categories, measuring and storing information as data on digital infrastructure. When we find a data collection enriched with metadata information or specific labels, we always need to remember that someone has either directly provided those labels or those have been automatically assigned by a tool trained on other manual labels.\n",
    "To give a specific example, the famous ImageNet dataset, central component for the development of many well known image recognition pipelines in the last ten years, relies on two pillars:\n",
    "- a taxonomy developed since 1985 as part of the lexical database WordNet, which provides a top-down hierarchical structure of concepts (\"chair\" is under artifact->furnishing->furniture->seat->chair)\n",
    "- an enormous amount of cheap workforce provided by Amazon Mechanical Turk.\n",
    "\n",
    "ImageNet is not an abstract resource, but the result of a gigantic effort and the specific representation of the World of *1)* the people who have designed WordNet, *2)* the researchers who have decided which WordNet categories are included and which are not in ImageNet and *3)* the many, many annotators who have selected which images associate to concepts like \"brother\", \"boss\", \"debtor\", \"drug-addict\" and \"call girl\", all included both in WordNet and ImageNet (at least until 2019).\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae069f86",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61d5b233",
   "metadata": {},
   "source": [
    "## Data Science\n",
    "\n",
    "We use the term to refer to a varied ensemble of practices, methodologies and tools that may be used to learn from or about data.\n",
    "    \n",
    "![The data science hierarchy of needs](../../figures/m1/pyramid_of_needs.png)\n",
    "\n",
    "<details>\n",
    "\n",
    "Having established that the necessary premise of data science is its relationship with data, the other fundamental component is constituted by a broad and multifaced ensemble of practices, methodoloogies and tools that, combined together, can lead to obtain \"new insights\" from or about a given dataset. If we consider Monica Rogati's representation of the \"Data science hierarchy of needs\" we can see that while developing new machine learning models sits at the top of the pyramid, methaphorically becoming the most visible component of a data scientist's work, this actually relies on many other steps, which we briefly introduce here and will be discussed in details in modules 2, 3 and 4.\n",
    "\n",
    "</details>\n",
    "\n",
    "### Collecting and Storing\n",
    "\n",
    "- Data collection and storage is (often) part of our job\n",
    "- If data needs to be generated in the first place, this should be an entirely different project!\n",
    "\n",
    "![newspapers](../../figures/m1/newspapers.jpeg) [Image link](https://blogs.bl.uk/thenewsroom/2019/07/moving-from-a-newspaper-collection-to-a-news-collection.html)\n",
    "\n",
    "\n",
    "<details>\n",
    "\n",
    "Part of the work of a data scientist is knowing the challenges and hurdles involved in data collection and storage. While, depending on the size of the team, such practices might be taken care of by software engineers or data curators, it is essential that we know who owns the data, which restrictions apply, how a resource should be stored for long-term preservation and made available to collaborators, how complex it would be to set up a secure environment such as a Data Safe Haven. In small team contexts, as data scientists we often take care directly of such responsibilities. Data collection additionally implies also data generation, in settings where the research team aims to produce a new dataset (instead of acquiring one already available). This would imply an even larger set of skills, ranging from selecting a representative sample, preparing annotation guidelines, hiring and monitoring the work of annotators, measuring their agreement and finding ways of improving their performance, etc. Our course does not cover such aspects because in many settings if data needs to be generated in the first place (through a data collection and annotation task for instance), that would become an independent project on its own.\n",
    "</details>\n",
    "\n",
    "### Processing and Exploring\n",
    "\n",
    "- Data cleaning implies actions such as: removing, normalising, ignoring, structuring, correcting\n",
    "- This is an incredibly important and often undervalued part of our job\n",
    "- Data exploration allows you to know the collection under study\n",
    "- So that you can use it beyond its original purpose\n",
    "\n",
    "![cleaning](../../figures/m1/cleaning.jpeg) [Image link](https://www.nytimes.com/2021/10/29/technology/apple-polishing-cloth.htmll)\n",
    "\n",
    "<details>\n",
    "\n",
    "Another famous expression in the community is \"data cleaning\" and many practicioners would say that 80% of their time is spent processing, wrangling, cleaning and preparing raw data to be used, by bringing structure in an unstructured chaos. While we do such steps, which often imply removing missing values in tables, ignoring images with inconsistent annotations, normalising labels to binary options, skipping words that might contained OCR errors in documents, etc, we should always think what we are losing by imposing our \"clean\" vision. Cleaning data means that we are imposing our control over a given collection and explicitly (or more often implicitly) shaping it following our own definition of \"clean\". Additionally note that, even if this task takes generally the largest part of a data scientist's work, it is often undervalued and, especially in an academic context, it is often done rapidly as a first stage in order to reach the data exploration and model building phases. Only issues emerging in these later phases would bring the research team to re-consider going through and improving the pre-processing step.\n",
    "\n",
    "For many disciplines and companies, the new availability of large datasets is absolutely unprecedented. While we will focus later on how this is changing science as a whole, for the moment it is important to understand that defining new research questions or business goals is very complex, as without data exploration you often don't know what is contained in the data and what's not, how this could be used and which new insight you could derive. If we take an example directly from our work at the Turing, [Project Odysseus](https://www.turing.ac.uk/research/research-projects/project-odysseus-understanding-london-busyness-and-exiting-lockdown) relies on information on the level of activity in London during the pandemic, which is derived from data collected from JamCam cameras, traffic intersection monitors, and aggregate GPS activity which were initially adopted by another Turing project, the [London Air Quality](https://www.turing.ac.uk/research/research-projects/london-air-quality) project. Knowing your data collection, the way it has been created and the additional information it might contain is an essential skill for a data scientist. For this reason in Module 3 we will focus on data exploration techniques, to help data scientists get a better understanding of the collection, allow collaborators to move from a general intuition to a specific question and allow serendipitous discoveries.\n",
    "\n",
    "</details>\n",
    "\n",
    "### Modeling\n",
    "\n",
    "- Often presented as the core activity of a data scientist\n",
    "- We build models with a specific goal in mind\n",
    "- And (properly!) assess which solution is the best, in a given setting\n",
    "\n",
    "\n",
    "![free_lunch](../../figures/m1/free_lunch.jpg) [Image link](https://fineartamerica.com/featured/theres-no-such-thing-as-a-free-lunch-dana-fradon.html)\n",
    "\n",
    "<details>\n",
    "\n",
    "Modeling is generally considered the core activity of a data scientist. While we have already stressed the fact that modeling is just one of the steps of our work, it is also important to remark from the beginning on two aspects of modeling that are inherently present in each data science activity: first of all, that we build models with a specific goal in mind. In fact we focus a large part of our project scoping activities (which we will see in Lesson 1.2) on defining a specific question, a corresponding data science task and a measure of success. So the modeling that we do is always clearly focused to address a specific, well defined need. \n",
    "\n",
    "Second, and highly related, modeling is about comparing solutions to determine what works \"best\" in a given setting. For instance, if the task is segmenting cells given a microscope image, we would first implement and test a series of established approaches for the task and then we would assess whether, for instance, recent advancements in the field of computer vision would offer improvements in this specific setting. As we will remark later, the job of a data scientist is usually not to improve over a given state-of-the-art method (this might be the job of a researcher in machine learning for computer vision for instance), but to implement and assess the current \"best\" approach for a given task. In certain situations, this might lead to an improvement over the state-of-the-art or it might just reconfirm that a very well known and established baseline remains the most reliable solution for a problem.\n",
    "\n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16ede84",
   "metadata": {},
   "source": [
    "## Data science in research\n",
    "\n",
    "- Never-experienced-before availability and often abundance of data \n",
    "- The emergence of a figure (the data scientist) able to work with it\n",
    "- Since the late 2000s academia started discussing \"a new way of acquiring knowledge\"\n",
    "\n",
    "![big_data](../../figures/m1/big_data.png) [Image link](https://www.nytimes.com/2012/02/12/sunday-review/big-datas-impact-in-the-world.html)\n",
    "\n",
    "\n",
    "### A Fourth Paradigm?\n",
    "\n",
    "From \"Beyond the Data Deluge\" (Bell et al., 2009, Science):\n",
    "\n",
    "- Experimental and theoretical science as the basic research paradigms for understanding nature\n",
    "- Recently, computer simulations have become an essential third paradigm\n",
    "- Now a fourth paradigm is emerging, consisting of the techniques and technologies needed to perform data-intensive science\n",
    "\n",
    "![fourth_para](../../figures/m1/fourth_para.jpg) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<details>\n",
    "\n",
    "As Bell, Hey and Szalay (2009) said in a famous short article in Science, for a long time \"scientists have recognized experimental and theoretical science as the basic research paradigms for understanding nature. In recent decades, computer simulations have become an essential third paradigm [...]\" and now \"a fourth paradigm is emerging, consisting of the techniques and technologies needed to perform data-intensive science. Today, some areas of science are facing hundred- to thousandfold increases in data volumes from satellites, telescopes, highthroughput instruments, sensor networks, accelerators, and supercomputers, compared to the volumes generated only a decade ago. [...] Other research fields also face major data management challenges. In almost every laboratory, “born digital” data proliferate in files, spreadsheets, or databases stored on hard drives, digital notebooks, Web sites, blogs, and wikis. The management, curation, and archiving of these digital data are becoming increasingly burdensome for research scientists.\" \n",
    "\n",
    "</details>\n",
    "\n",
    "\n",
    "### Data-Driven Science?\n",
    "\n",
    "From \"The end of Theory\" (Anderson, 2008, Wired)<sup>[2](#References)</sup>:\n",
    "\n",
    "- Are we at the \"end of theory\" and the advent of \"data-driven\" science?\n",
    "- Is it true that \"Correlation is enough\" and that \"we can analyze the data without hypotheses about what it might show\"?\n",
    "- There is no need for a priori theory, models or hypotheses\n",
    "\n",
    "![theory](../../figures/m1/theory.jpg) \n",
    "[Image link](https://www.wired.com/2008/06/pb-theory/)\n",
    "\n",
    "<details>\n",
    "\n",
    "In just a few years the discussion around the fourth-paradigm has moved to even a more contentious topic: The \"end of theory\" and the advent of \"data-driven\" science. Such discussion was started by a provocative article by Chris Anderson on Wired (2008) containing statements such as \"Petabytes allow us to say: ‘Correlation is enough. We can analyze the data without hypotheses about what it might show. We can throw the numbers into the biggest computing clusters the world has ever seen and let statistical algorithms find patterns where science cannot. Correlation supersedes causation, and science can advance even without coherent models, unified theories, or really any mechanistic explanation at all.\" As Kitchin (2014) has highlighted in similar tones there is \"a powerful and attractive set of ideas at work in the empiricist epistemology that runs counter to the deductive approach that is hegemonic within modern science:\n",
    "\n",
    "- Big Data can capture a whole domain and provide full resolution;\n",
    "- there is no need for a priori theory, models or hypotheses;\n",
    "- through the application of agnostic data analytics the data can speak for themselves free of human bias or framing, and any patterns and relationships within Big Data are inherently meaningful and truthful;\n",
    "- meaning transcends context or domain-specific knowledge, thus can be interpreted by anyone who can decode a statistic or data visualization.\n",
    "\n",
    "</details>\n",
    "\n",
    "### Data-Driven Science with a Critical Mindset\n",
    "\n",
    "- Our perception of data science in society and research has drastically changed\n",
    "- The core of our course will be on how to approach data, methods and questions in a critical way\n",
    "\n",
    "\n",
    "![fourth_para](../../figures/m1/atlas_ai.png) \n",
    "[Image link](https://www.cambridge.org/core/journals/mrs-bulletin/article/abs/nomad-the-fair-concept-for-big-datadriven-materials-science/1EEF321F62D41997CA16AD367B74C4B0)\n",
    "\n",
    "<details>\n",
    "\n",
    "Reading such statements now might leave us speechless, especially after a few years of discussions around the limitations of computational methods, of biases embedded in trained models, on the fact that data don't speak for themselves or that we need experts in defining the scope of the study and interpret the results, and of the impact that neglecting or undervaluing all these things has on science and society as a whole. In our course we will spend a lot of time focusing on how to approach data, methods and research questions in a highly critical way to ensure (for the best we can) that the new findings that we encounter are reliable and reproducible.\n",
    "\n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029513e1",
   "metadata": {},
   "source": [
    "## Research data scientist\n",
    "\n",
    "- We are often central element in research projects (connecting data providers, domain experts, final users)\n",
    "- We will be in the position of asking \"why\" people want to use data science approaches\n",
    "- We contribute in shaping research directions and guaranteing reproducibility\n",
    "\n",
    "![reg](../../figures/m1/reg.png) \n",
    "\n",
    "\n",
    "<details>\n",
    "As we have higlighted in this introduction to the first module, the role of a data scientist in research brings with it many responsibilities. We will often be the central element in the projects we are involved with, connecting data providers, domain experts and final users and it will be our duty to understand all challenges involved in each step to facilitate cross-disciplinary communication. Even more importantly, in such position we will be in the position of asking \"why\" people want to use data science methods to address a particular research question, always ensuring that people are aware of both the limitations and the risk that such methodological frameworks might further emphasize established social hierarchies in very subtle ways.\n",
    "\n",
    "If we consider the large-scale [Living with Machines](https://www.turing.ac.uk/research/research-projects/living-machines) project, a five-year study on the Industrial Revolution using data-driven approache and which has over twenty members and currently five REG members working on it, we will see in how many different aspects they are now become essential elements. RDS are for instance highly involved in data acquisition, classification (based on the level of sensitivity) and storage. They coordinate the use of a secure environment (a [Data Safe Haven](https://www.turing.ac.uk/research/research-projects/data-safe-havens-cloud)) to work on copyright protected collections and ensure the secure egress of all outputs from this environment. They are also responsible of organising acquired materials in databases and of providing the necessary skills to other researchers on the project so that they will be able to access such resources easily. As the project employs many different types of data sources (digitised maps, newspaper articles and tables of census records), RDS develop tools for facilitating their adoption, for instance [historical language models](https://github.com/Living-with-machines/histLM), methods for dealing with [fuzzy string matching](https://github.com/Living-with-machines/DeezyMatch) or for [sampling resources](https://github.com/Living-with-machines/PressPicker_public)) as well as they contribute to research papers based on data science methods (see for instance: [Living Machines: A study of atypical animacy](https://arxiv.org/pdf/2005.11140.pdf) or [Maps of a Nation?](https://web.archive.org/web/20210423221450id_/https://watermark.silverchair.com/vcab009.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAArcwggKzBgkqhkiG9w0BBwagggKkMIICoAIBADCCApkGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQM1AlAgUtq5ba0pasxAgEQgIICal_obCGyNK5g70TgQwLWGBcI748EBTsJcVj0MKBXtN2ktjgLdQxm8MkLSEMf65JLQZZifGp_UZfGzn6K6ZeHQ04ODsAElr2wIqj0cA0dFHsAV9pC1hbbWuvEv5QwzrAGRDAg4nh2ALPok39NLd4CKzDv0zjeKLUQOMyoxxUPaIXA4KDkL1aq1EXbcjDdSIB65L9e8K5F0bfpPToIMdck_QztBtCm05JVYJMIWAOWDrshmAbnDVoz4STt99fCj9mML860iRGvlcOExguDKTLtFVxxMuKHRY6tduTApzTiAsGhgFTKE1dZ47pzZVV_giTA9od6U9BQbhpyJ1spDoKHf4RGjecgO7hbi3DdrN73BzOEmBsnv9uUhpKGOYBtd4PMIgXh-SNFpMtWQ2SdoOLxKSmM-lN8LdnyMILUqxneyzMMd-oKGOLJodHP71Xy8Y97N3uqnLtZZ_7Fcb87BnLRNQv5So3udV0UzJWxOxyJwB3iym2mmH1XKwrv2xLMY7hKMNBCp87qNZcUVHZitcjNh40HgPualpIjU_sibvokmEWCiBo1gTZmKf5kr2f6JtO3W9chQaKTJpqVf-LCCq2ABiURFDewU11SGg-81jot7lLHH22QSetHc8UlyRZvUo7bkxxGnsjNnRkL8JNUJyl2nnGYUAV2TWOwU0k_tXIFCNEWGlgwr9RCqat0DtjiQqPgOeL4l72gFyWDQ4VPfFmZELBgoxzoe8HrCJRbsuicqbqV4jn6C4ui55T17hKnJtkm68YaT-3S8ni4tNX3gGZyBnCps6E3Je9oyPOwU8ArXRs42G1kzlHzW2IsFg). On such works, RDS not only build benchmarks and assess the performance of the methods employed but especially contribute in shaping the research goal from the very beginning and make sure that results are reprodubile and limitations are clearly discussed in the paper.\n",
    "\n",
    "Finally, they also take under their wings many project management tasks, for instance planning and leading specific sub-projects, taking care of scheduling milestones, deliverables and handling stake-holders expectations. While Living with Machines remains almost a unicum at the Turing for its size and its interdisciplinary dynamics, it offers a clear overview of the many many skills, duties and responsibilities that are part of our job.\n",
    "\n",
    "In order to offer you a broad overview of such duties across Research Data Science projects, in module 1.2 we will start by examining the importance of the project lifecycle and how being proactive in shaping it around each specific research project will guarantee that we will be able to at least deliver the minimum valuable outcome that has been agreed initially by all parties involved. Due to the fact that data science is so present in public conversations in and out of academia, it is also our role to fight against the many myths and toxic narratives that are highly common regarding the field. On the opposite, our role involves making our collaborators aware of the many risks and challenges that data science poses. For this reason, module 1.3 will address many aspects of the current debate about Equality, Diversity and Inclusion (EDI) in data science. Finally, as we have already remarked, being a research data scientist implies working in highly interdisciplinary collaborative environments, so for this reason the last submodule, 1.4, will conclude discussing best practices for collaborative coding. \n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f713458c",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Rogers, A. (2021). Changing the World by Changing the Data. arXiv preprint arXiv:2105.13947.\n",
    "\n",
    "\n",
    "2. Anderson, C. (2008). The end of theory: The data deluge makes the scientific method obsolete. Wired magazine, 16(7), 16-07.\n",
    "\n",
    "3. Bell, G., Hey, T., & Szalay, A. (2009). Beyond the data deluge. Science, 323(5919), 1297-1298.\n",
    "\n",
    "4. Crawford, K. (2021). The Atlas of AI. Yale University Press.\n",
    "\n",
    "5. D'ignazio, C., & Klein, L. F. (2020). Data feminism. MIT press.\n",
    "\n",
    "6. Kitchin, R. (2014). Big Data, new epistemologies and paradigm shifts. Big data & society, 1(1).\n",
    "\n",
    "7. Wickham, H. (2014). Tidy data. Journal of statistical software, 59(1), 1-23.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('playground')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "bfb6be6a1e2928ff2d2ab7904db3c9037c4b5ca4f399bd5e7064365a54a3f091"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
