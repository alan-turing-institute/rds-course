{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2.4.4 Image Data\n",
    "\n",
    "Earlier in this module, we introduced image data as a 2d or 3d tensor\n",
    "representing pixel values.\n",
    "\n",
    "Commonly, we may wish to resize, reshape, normalise or standardise image\n",
    "data.\n",
    "\n",
    "`{admonition} Normalisation vs Standardisation *Normalisation* will typically rescale the values into a range of [0,1]. *Standardisation* will typically rescale data to have a mean of 0 and a standard deviation of 1 (unit variance).`\n",
    "\n",
    "## Resizing (and Resampling)\n",
    "\n",
    "\\`\\`\\`{admonition} Resizing vs Resampling The term *resize* can be used\n",
    "to refer to changing the physical size of an image without changing the\n",
    "number of pixels. In these contexts, *resampling* is used to refer to\n",
    "the operation that changes the total number of pixels.\n",
    "\n",
    "However, many popular Python image libraries use the term *resize* to\n",
    "refer to changing the total number of pixels. We will follow this\n",
    "convention.\n",
    "\n",
    "\n",
    "    When resizing, interpolation methods determine pixel values when upsampling or downsampling an image. In the case of\n",
    "     upsampling, the method determines the value for \"new\" pixels. \n",
    "     \n",
    "     ```{margin} OpenCV Interpolation\n",
    "    The OpenCV docs provide some info on [resizing](https://docs.opencv.org/2.4.13.7/modules/imgproc/doc/geometric_transformations.html#resize), with brief mention of interpolation methods.\n",
    "    A friendly explanation of the interpolation methods available is given in [this article](https://www.pyimagesearch.com/2021/01/20/opencv-resize-image-cv2-resize/) under the \"Comparing OpenCV interpolation methods\" heading.\n",
    "\n",
    "For example, using the OpenCV library:\n",
    "\n",
    "\\`\\`\\`{code-cell} ipython3 import cv2 from matplotlib import pyplot as\n",
    "plt\n",
    "\n",
    "im = cv2.imread(“./data/smiley_16.png”) print(f”loaded data of shape:\n",
    "{im.shape}“)\n",
    "\n",
    "# resize using NEAREST interpolation method\n",
    "\n",
    "im_64_nearest = cv2.resize(im, (64,64), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "# resize using CUBIC interpolation method\n",
    "\n",
    "im_64_cubic = cv2.resize(im, (64,64), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "    (code to display hidden below)\n",
    "\n",
    "    ```{code-cell} ipython3\n",
    "    :tags: [hide-input]\n",
    "\n",
    "    # display with matplotlib\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15, 5), dpi=80, sharex=True, sharey=True,)\n",
    "    ax[0].imshow(im, cmap='gray')\n",
    "    ax[0].set_title(\"16x16 original\")\n",
    "    ax[0].axis('off')\n",
    "\n",
    "    ax[1].imshow(im_64_nearest)\n",
    "    ax[1].set_title(\"64x64 method=nearest\")\n",
    "    ax[1].axis('off')\n",
    "\n",
    "    ax[2].imshow(im_64_cubic)\n",
    "    ax[2].set_title(\"64x64 method=cubic\")\n",
    "    ax[2].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "## Standardisation\n",
    "\n",
    "Image processing will often expect the data to be standardised.\n",
    "\n",
    "As we’ve seen that our image data is represented in a numeric 2d or 3d\n",
    "tensor, we can standardise by converting the image to have zero mean,\n",
    "and unit variance.\n",
    "\n",
    "\\`\\`\\`{code-cell} ipython3 import cv2 from matplotlib import pyplot as\n",
    "plt import numpy as np\n",
    "\n",
    "im = cv2.imread(“data/flower.png”) \\# convert colour as we’re loading in\n",
    "BGR rather than RGB im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "means = np.mean(im, axis=(0,1), keepdims=True) stds = np.std(im,\n",
    "axis=(0,1), keepdims=True)\n",
    "\n",
    "print(f”means: {means}“) print(f”stds: {stds}“) print()\n",
    "\n",
    "# subtract means and divide by stds\n",
    "\n",
    "result = (im - means) / stds\n",
    "\n",
    "\n",
    "    (code to display hidden below)\n",
    "\n",
    "    ```{code-cell} ipython3\n",
    "    :tags: [hide-input]\n",
    "\n",
    "    # continue from last\n",
    "    # display with matplotlib\n",
    "    # scale range to [0,255] for display \n",
    "    for_vis = cv2.normalize(result, None, 0, 255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U) \n",
    "\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15, 5), dpi=80, sharex=True, sharey=True,)\n",
    "    ax[0].imshow(im, cmap='gray')\n",
    "    ax[0].set_title(\"original\")\n",
    "    ax[0].axis('off')\n",
    "\n",
    "    ax[1].imshow(for_vis)\n",
    "    ax[1].set_title(\"standardised (for display only)\")\n",
    "    ax[1].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "Some sanity checks (code and output) for standardisation hidden below.\n",
    "\n",
    "\\`\\`\\`{code-cell} ipython3 :tags: \\[hide-cell\\]\n",
    "\n",
    "### sanity checks\n",
    "\n",
    "# check new means and stds\n",
    "\n",
    "means, stds = cv2.meanStdDev(result)\n",
    "\n",
    "# check our new means are 0 (within given tolerance)\n",
    "\n",
    "np.testing.assert_allclose(means, 0, atol=1e-07) \\# check our new stds\n",
    "are 1 (within given tolerance) np.testing.assert_allclose(stds, 1)\n",
    "\n",
    "# show top left “pixel”\n",
    "\n",
    "print(f”original top left: {im\\[0, 0, :\\]}“) print(f”standardised top\n",
    "left: {result\\[0, 0, :\\]}“) print()\n",
    "\n",
    "\n",
    "     \n",
    "    However, for many deep learning tasks, it is common to standardise image data by using precomputed dataset means and standard deviations,\n",
    "    rather than calculate these for each image. For example, using the ImageNet values:\n",
    "\n",
    "    ```{code-cell} ipython3\n",
    "    import cv2\n",
    "\n",
    "    im = cv2.imread(\"data/flower.png\")\n",
    "    # convert colour as we're loading in BGR rather than RGB\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    imagenet_means = [0.485, 0.456, 0.406],\n",
    "    imagenet_stds = [0.229, 0.224, 0.225]\n",
    "\n",
    "    # assumes we're in range [0,1] rather than [0,255]\n",
    "    scaled = cv2.normalize(im, None, 0, 1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "\n",
    "    # subtract means and divide by stds\n",
    "    imagenet_result = (scaled - imagenet_means) / imagenet_stds\n",
    "    print(imagenet_result[0,0,:])\n",
    "\n",
    "\\`\\`\\`{code-cell} ipython3 :tags: \\[hide-input\\]\n",
    "\n",
    "# continue from last\n",
    "\n",
    "# display with matplotlib\n",
    "\n",
    "# scale range to \\[0,255\\] for display\n",
    "\n",
    "imagenet_for_vis = cv2.normalize(imagenet_result, None, 0, 255,\n",
    "norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15, 5), dpi=80,\n",
    "sharex=True, sharey=True,) ax\\[0\\].imshow(im, cmap=‘gray’)\n",
    "ax\\[0\\].set_title(“original”) ax\\[0\\].axis(‘off’)\n",
    "\n",
    "ax\\[1\\].imshow(imagenet_for_vis) ax\\[1\\].set_title(“ImageNet standarised\n",
    "(for display only)”) ax\\[1\\].axis(‘off’)\n",
    "\n",
    "plt.show() \\`\\`\\`\n",
    "\n",
    "We see that the image doesn’t appear to have been altered to the same\n",
    "extent as before. This is due to the ImageNet values being less skewed\n",
    "towards the blue channel.\n",
    "\n",
    "note: many packages like\n",
    "[torchvision](https://pytorch.org/vision/stable/) will have convenience\n",
    "methods to do standardisation/normalisation for you."
   ],
   "id": "97d62929-02a0-4fcf-b0c1-c48efcb72283"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
