{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "411f2a74",
   "metadata": {},
   "source": [
    "# 3.5 Walkthrough: visualisation for data exploration\n",
    "\n",
    "In this last section we are going dig back into our EQLTS survey dataset and use some of the data visualisation tools we covered in the previous sections to better understand our dataset. \n",
    "\n",
    "A reminder of our Research question:\n",
    "\n",
    "> We want to investigate the contribution of material, occupational, and psychosocial factors on the self reported health (SRH) across different European countries. We will use SRH information collected by the Wave 2 and 3 of the EQLTS survey, aware that they offer only a partial representation of European populations and that SRH is per-se a highly subjective indicator, difficult to compare across countries.\n",
    "\n",
    "  \n",
    "## Aside from Aldabe et al. paper\n",
    "\n",
    "We are using the Aldabe et al. 2011, paper as a guideline into our analysis, let's have a quick recap. \n",
    "The study uses the following variables:\n",
    "\n",
    "- The main model used socio-economic status information (occupation and education-level survey questions) and age to predict SRH (age was included to control for it).\n",
    "- Additional models were tested that included a rather large list of _material_, _occupational_ and _psychosocial_ variables to test if they mediate the relationship. See Table 1 in the paper.\n",
    "- The majority of responses were \"good\" health (81.14% of men; 76.91% of woman). \n",
    "\n",
    "We are interested in exploring predictors that are general (some of the questions are quite specific)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4027e31f",
   "metadata": {},
   "source": [
    "We can access the data by downloading the `csv` option from [here](https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=7724#!/details).\n",
    "You would have downloaded a folder with the following directory structure. Here we have only listed the files which we will use:\n",
    "\n",
    "```\n",
    "- UKDA-7724-csv\n",
    "    - csv # here is the data\n",
    "        - eqls_2011.csv\n",
    "    - mrdoc #here is additional info\n",
    "        - allissue #data dictionaries\n",
    "        - excel\n",
    "            - eqls_api_map.csv # description of what the column names mean\n",
    "            - eqls_concordance_grid.xlxs #described which variables were included in which waves and the mapping between waves\n",
    "        - pdf # user guide\n",
    "        - UKDA #study info\n",
    "```\n",
    "\n",
    "Unzip the data to `$PROJECT_ROOT/data` (where `$PROJECT_ROOT` is the root of the cloned github repository for this course).\n",
    "This should give you `$PROJECT_ROOT/data/UKDA-7724-csv` directory.\n",
    "\n",
    "In the data set there are 195 variables but many were not included in wave 3 - `eqls_concordance_grid.xlsx` states which.\n",
    "For simplicity in this example we will only use wave 3 data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4329579b",
   "metadata": {},
   "source": [
    "## Reading the data\n",
    "\n",
    "\n",
    "Let's start reading wave 3 data `eqls_2011.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "376adf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    " \n",
    "plt.style.use('seaborn')\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9297d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datafolder = '../../../data/UKDA-7724-csv/' # should match the path you unzipped the data to\n",
    "df = pd.read_csv(datafolder + 'csv/eqls_2011.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f07d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e6c3ee",
   "metadata": {},
   "source": [
    "## Variables, topics and groupings "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18fe5f6",
   "metadata": {},
   "source": [
    "We have a large number of variables (196) with coded names. We need to use the `eqls_api_map.csv` to understand what each of these columns mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e3335b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_map = pd.read_csv(datafolder + 'mrdoc/excel/eqls_api_map.csv', encoding='latin1')\n",
    "\n",
    "df_map.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463ed671",
   "metadata": {},
   "source": [
    "### Notes from the [User Guide](http://doc.ukdataservice.ac.uk/doc/7724/mrdoc/pdf/7724_eqls_2007-2011_user_guide_v2.pdf)\n",
    "\n",
    "\n",
    "- Variables are grouped into primary and secondary topics (e.g. Education - Higher and further).\n",
    "- Variables are _also_ grouped into variable groupings which differ slightly from the topics. \n",
    "\n",
    "- The topics are an attempt to succinctly describe the semantic domain of each variable. The variable groupings are slightly overlapping with these topics (e.g Health crops up twice), but also includes indicators such as 'Derived Variables', which clearly is a technical grouping rather than a topic. \n",
    "\n",
    "- Derived variables \"group numeric responses of other related variables or to collapse groupings of related categorical variables into fewer categories\". The derived variables are potentially useful, since they aim to:\n",
    "    - enhance the data quality by aggregating the responses into more usable and consistent format across both waves of the Survey\n",
    "    - provide a clearer structure of datasets by reducing the number of variables\n",
    "    - ensure confidentiality and anonymity of personal information and all respondents\n",
    "- The derived variables are not necessarily the most important questions, they simply occur when the are many related questions that can be aggregated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea676558",
   "metadata": {},
   "source": [
    "Let's take a look a the grouping os variables and how many questions are in each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587196a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all Groups\n",
    "sns.countplot(y=\"VariableGroupValue\", data=df_map, palette=\"Accent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56e379f",
   "metadata": {},
   "source": [
    "`Public Services` are the group that has the highest number of questions associated to it, followed by `Employment and Work-Life Balance`. `Education` and `Health` appear to have just a few questions. \n",
    "\n",
    "Let's look now how the questions distribute around Topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d85a291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all topics\n",
    "sns.countplot(y=\"TopicValue\", data=df_map, palette=\"Accent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1fafb5",
   "metadata": {},
   "source": [
    "Now, let's explore how the `TopicValue` and `VariableGroupValue` map to each other. Furthermore, since the derived variables were made specifically to make the dataset easier to use let's have a look at these and see how they map onto _material_, _occupational_, and _psychosocial_ factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb3b9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap1_data = pd.pivot_table(df_map, index=['TopicValue'],values='VariableName',columns=['VariableGroupValue'], aggfunc=lambda x: len(x.unique()))\n",
    "sns.heatmap(heatmap1_data, cmap=\"YlGnBu\")\n",
    "plt.xticks(\n",
    "    rotation=45, \n",
    "    horizontalalignment='right',\n",
    "    fontweight='light',\n",
    "    #fontsize='x-large'  \n",
    ")\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d89042b",
   "metadata": {},
   "source": [
    "As expected there is not a 1:1 mapping between these two categories, and we only have a subset of topics covered by our derived variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ed0584",
   "metadata": {},
   "source": [
    "If we revisit the table above with some consideration we can sensibly group the derived variable topics as follows.\n",
    "\n",
    "- Material\n",
    "    - Economics - Income, property and investment\n",
    "    - Environment, conservation and land use - Land ...\n",
    "    - Housing\n",
    "- Occupational\n",
    "    - Employment and labour - General\n",
    "- Psychosocial\n",
    "    - Social stratification and groupings - General\n",
    "    - Society and culture - Social attitudes and beh..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5871df6b",
   "metadata": {},
   "source": [
    "Let's have a closer look at these variables using `eqls_2011_ukda_data_dictionary.rtf`. We have also had a manual scan of `eqis_api_map` and included promising looking variables in the list below.\n",
    "\n",
    "\n",
    "#### Material Variables\n",
    "- `Y11_Deprindex`:  `Y11_Q59a` to `Y11_Q59f` ask the question 'Can house afford it if you want it?', with six examples (home heating, holiday, replacing goods, good food, new clothes, hosting friends). The responses are categorical `1` (YES) or `2` (NO). The `Y11_Deprindex` is a count of the number of yes responses.\n",
    "- `Y11_RuralUrban`: This variable simply condenses a previous question from four categories into two categories - `1` (rural) or `2` (urban). \n",
    "- `Y11_Accommproblems`: `Y11_Q19a` - `Y11_Q19f` asks a `1` (YES) or `2` (NO) question about accommodation problems, with six examples. This variable is a count.\n",
    "- `Y11_HHsize`: Household size including children (overlaps with social). Ranges from 1-4 where 4 is 4 or more.\n",
    "- `Y11_Q32`: related to above, number of children. Ranges from 1-5 where 5 is 5 or more.\n",
    "- `Y11_Incomequartiles_percapita` ranges from 1 (1st quartile) to 4 (4th quartile). \n",
    " \n",
    "#### Occupational Variables\n",
    "- `DV_Q7`: Count from a couple of working hours questions. Varies from 80-5. \n",
    "- `Y11_ISCEDsimple`: Education levels based on the International Standard Classification of Education (ISCED). Ranges from 1-8. Confusing, 1-7 is from no to high education. 8 means N/A.\n",
    "- `Y11_Education`: related to above but less granular. 1-3 are primary -> tertiary. 4-6 are various catch answers.\n",
    "\n",
    "#### Pychosocial Variables\n",
    "- `Y11_SocExIndex`: average score from four social exclusion question measures on a 5 scale response (1 = strongly disagree, 5 = strongly agree). \n",
    "- `Y11_MWIndex`: There is a set of five questions where the respondents state degree of agreement, measures on a six-point scale. The mental well-being scale converts these to a value between 0 - 100.\n",
    "\n",
    "So, this gives us **11 variables**, with two pairs that are variations of each other. This is enough to play with and try to build a simple model (see Module 4).\n",
    " \n",
    "#### Other\n",
    "- Age (5 categories). `Y11_Agecategory`\n",
    "- Gender. `Y11_HH2a`\n",
    "- Marital Status. `Y11_Q31`. \n",
    "- Country. `Y11_Country`. \n",
    "\n",
    "To make the manipulation easier we select a subset of the data with only the variables we want and rename them into something more readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4d2bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_map = {\"Y11_Q42\": \"SRH\",\n",
    "           'Y11_Deprindex': 'DeprIndex',\n",
    "           \"Y11_RuralUrban\": \"RuralUrban\",\n",
    "           \"Y11_Accommproblems\": 'AccomProblems',\n",
    "           \"Y11_HHsize\": \"HouseholdSize\",\n",
    "           \"Y11_Q32\": \"Children\",\n",
    "           \"Y11_Incomequartiles_percapita\" : \"IncomeQuartiles\",\n",
    "           \"DV_Q7\":\"WorkingHours\",\n",
    "           \"Y11_ISCEDsimple\":\"ISCED\",\n",
    "           \"Y11_Education\": \"Education\",\n",
    "           \"Y11_SocExIndex\":\"SocialExclusionIndex\",\n",
    "           \"Y11_MWIndex\": \"MentalWellbeingIndex\",\n",
    "           \"Y11_Agecategory\":\"AgeCategory\",\n",
    "           \"Y11_HH2a\":\"Gender\",\n",
    "           \"Y11_Q31\":\"MaritalStatus\",\n",
    "           \"Y11_Country\":\"Country\",\n",
    "           \"DV_Q43Q44\": \"ChronicHealth\"\n",
    "}\n",
    "\n",
    "df.rename(columns=var_map, inplace=True)\n",
    "df_set = df[var_map.values()]\n",
    "df_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedfd793",
   "metadata": {},
   "source": [
    "## Exploring different countries \n",
    "\n",
    "Our data contains 35 different european countries. Let's take a look at the differences of some of our variables of interest for the different countries in the data. \n",
    "\n",
    "First we need to map the country code values to their name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2308740e",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_factory={\n",
    "            1.0: \"Austria\",\n",
    "            2.0: \"Belgium\",\n",
    "            3.0: \"Bulgaria\",\n",
    "            4.0: \"Cyprus\",\n",
    "            5.0: \"Czech Republic\",\n",
    "            6.0: \"Germany\",\n",
    "            7.0: \"Denmark\",\n",
    "            8.0: \"Estonia\",\n",
    "            9.0: \"Greece\",\n",
    "            10.0: \"Spain\",\n",
    "            11.0: \"Finland\",\n",
    "            12.0: \"France\",\n",
    "            13.0: \"Hungary\",\n",
    "            14.0: \"Ireland\",\n",
    "            15.0: \"Italy\",\n",
    "            16.0: \"Lithuania\",\n",
    "            17.0: \"Luxembourg\",\n",
    "            18.0: \"Latvia\",\n",
    "            19.0: \"Malta\",\n",
    "            20.0: \"Netherland\",\n",
    "            21.0: \"Poland\",\n",
    "            22.0: \"Portugal\",\n",
    "            23.0: \"Romania\",\n",
    "            24.0: \"Sweden\",\n",
    "            25.0: \"Slovenia\",\n",
    "            26.0: \"Slovakia\",\n",
    "            27.0: \"UK\",\n",
    "            28.0: \"Turkey\",\n",
    "            29.0: \"Croatia\",\n",
    "            30.0: \"Macedonia (FYROM)\",\n",
    "            31.0: \"Kosovo\",\n",
    "            32.0: \"Serbia\",\n",
    "            33.0: \"Montenegro\",\n",
    "            34.0: \"Iceland\",\n",
    "            35.0: \"Norway\",\n",
    "        }\n",
    "\n",
    "df_set[\"Country_cat\"] = df_set[\"Country\"].apply(lambda x: default_factory.get(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0264a5",
   "metadata": {},
   "source": [
    "Let's compare the distributions of the Self Reported Health, Deprivation Index and Social Exclusion Index for the different countries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8467f1da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(3,1,figsize =(35,20),sharex=True)\n",
    "\n",
    "chart = sns.violinplot(x=\"Country_cat\", y=\"SRH\", data=df_set,ax=axes[0])\n",
    "sns.boxplot(x=\"Country_cat\", y=\"DeprIndex\", data=df_set,ax=axes[1])\n",
    "sns.boxplot(x=\"Country_cat\", y=\"SocialExclusionIndex\", data=df_set,ax=axes[2])\n",
    "plt.xticks(\n",
    "    rotation=45, \n",
    "    horizontalalignment='right',\n",
    "    fontweight='light',\n",
    "    fontsize='x-large'  \n",
    ")\n",
    "None "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6614b48",
   "metadata": {},
   "source": [
    "In the figures above we can observe a large variability between the variables of interest for our study. Taking this into consideration, and for simplicity of the model we are going to build in Module 4 in the rest of this section we will focus only in one country, the UK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe4644e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uk = df_set.query('Country == 27')\n",
    "df_uk.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8409f46",
   "metadata": {},
   "source": [
    "## Missingness\n",
    "\n",
    "Lets now investigate the missingness of our variables of interest. There are three categories of missing data: Missing Completely at Random (MCAR), Missing at Random (MAR), Missing Not at Random (MNAR). Understanding the type of missigness present in our dataset is fundamental to justify the use (or dismissal) of a variable in our model. Furthermore, it will help inform the strategy for any kind of imputation done to avoid missing useful data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5980dde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following command shows missing/non-missing values in two colors.\n",
    "plt.figure(figsize=(40,40))\n",
    "sns.displot(\n",
    "    data=df_uk.isna().melt(value_name=\"missing\"),\n",
    "    y=\"variable\",\n",
    "    hue=\"missing\",\n",
    "    multiple=\"fill\",\n",
    "    aspect=1.25, \n",
    ")\n",
    "plt.show()\n",
    "\n",
    "print ('Percentage of missing values')\n",
    "eqls_null_counts = df_uk.isnull().sum() / len(df_uk)\n",
    "print(eqls_null_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ef5198",
   "metadata": {},
   "source": [
    "Working Hours is mostly missing. It is derived from two variables, `Y11_Q7`, `Y11_Q7b` (a secondary job). A reason for this is that if the person does not have a second job then the total working hours is given as NaN. Let's explore this further. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d46e8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hours = df[['WorkingHours','Y11_Q7','Y11_Q7b']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeeae583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following command shows missing/non-missing values in two colors.\n",
    "plt.figure(figsize=(40,40))\n",
    "sns.displot(\n",
    "    data=df_hours.isna().melt(value_name=\"missing\"),\n",
    "    y=\"variable\",\n",
    "    hue=\"missing\",\n",
    "    multiple=\"fill\",\n",
    "    aspect=1.25, \n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1d6537",
   "metadata": {},
   "source": [
    "### Dealing with Missingness\n",
    "\n",
    "In the figure above we can see that only about 40% of respondents filled out the working hours for the first job. Given the large amount of missing data for this variable is probably best to not use it. \n",
    "\n",
    "Similarly, about 24% of people do not have an estimated `IncomeQuartiles`. Perhaps these are also unemployed? We could impute, but even sophisticated imputation methods (such as drawing from a distribution specified by the existing values) will introduce randomness (unwanted noise) into the relationships across variables. We could calculate the covariance matrix of the existing data and use that to impute. But similarly that will artificially enhance existing relationships and mean that you are more prone to overfitting. \n",
    "\n",
    "If we decide to drop the rows with missing data we need to carefully balance any increase of noise by imputation to the loss of statistics of dropping these rows. Furthermore, a research data scientist on this project should try to work with domain experts to uncover if there were any systemic reasons why some entries were missing and therefore by dropping rows we are removing a sub-population from the dataset.\n",
    "\n",
    "> For example, is it the people that do not have jobs that don't have incomes? Or perhaps jobless respondents are classed as the first quartile income and it is something else? This should be done before any imputation methods are considered so that we could assess the extent to which the imputation method is distorting both the distribution of the `IncomeQuartiles` predictor _and_ the joint distribution of `IncomeQuartiles` and the other variables.\n",
    "\n",
    "In terms of the the missingness jargon mentioned above (MCAR, MAR, MNAR) the only place where is safe to either drop or blindly impute is when data is missing completely at random in a small scale. And this is almost **never** the case.\n",
    "\n",
    "As we are lacking some of this information for this example and a a sceptic of adding data just to make your regression work we only select the data where `IncomeQuartiles` exists if I was to assess `IncomeQuartiles` as a variable.\n",
    "\n",
    "Let's compare `IncomeQuartiles` to `DeprIndex`. They both speak to finances and `DeprIndex` could be used as a replacement.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbf91f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean(data, **kws):\n",
    "    mn = np.nanmean(data.SRH.values)\n",
    "    ax = plt.gca()\n",
    "    ax.axvline(mn, c = (.6,.6,.6), ls ='--')\n",
    "\n",
    "g = sns.FacetGrid(df_uk, col=\"IncomeQuartiles\", sharey=False)\n",
    "g.map_dataframe(sns.histplot, 'DeprIndex',binwidth=1,binrange=[-0.5,6.5])\n",
    "\n",
    "    \n",
    "g.map_dataframe(plot_mean)\n",
    "g.set_axis_labels(\"Deprivation\", \"Count\")\n",
    "plt.show()\n",
    "\n",
    "g = sns.FacetGrid(df_uk, col=\"DeprIndex\", sharey=False)\n",
    "g.map_dataframe(sns.histplot, 'IncomeQuartiles',binwidth=1,binrange=[0.5,4.5])\n",
    "\n",
    "    \n",
    "g.map_dataframe(plot_mean)\n",
    "g.set_axis_labels(\"IncomeQuartiles\", \"Count\")\n",
    "plt.show()\n",
    "\n",
    "print(df_uk[['IncomeQuartiles','DeprIndex']].corr(method='spearman'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9811e2",
   "metadata": {},
   "source": [
    "From the above figure we can see that the distribution of `DeprIndex` shifts to the left as the income quartile increases (even though zero is the mode throughout). We have plotted it both ways round so better see the relationship. \n",
    "\n",
    "Though with such a small range of values a correlation is a little unreliable (and is pushed to lower values), we use Spearman's rank correlation as a rough assessment of whether scoring higher on `IncomeQuartiles` means that one scores higher on the `DeprIndex`. You can see that the correlation is -0.4. This correlation will be dampened by the mode being zero on the `DeprIndex`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7508e67b",
   "metadata": {},
   "source": [
    "There is a low amount of data missing in the other variables, with the highest being `DeprIndex` at 7.6%. If we were to only include rows with a full set of data we would be losing around 11% of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3dda13",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_len = len(df_uk)\n",
    "df_model = df_uk.drop(columns=['WorkingHours','IncomeQuartiles']).dropna()\n",
    "print(f\"Number of Rows: {len(df_model)}\")\n",
    "print(f\"Percentage excluded: {((pre_len - len(df_model)) / pre_len)*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adolescent-assets",
   "metadata": {},
   "source": [
    "### Other questions to consider"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fantastic-sauce",
   "metadata": {},
   "source": [
    "The presence and pattern of missing data in a dataset can contain valuable information. Before trying to remove or replace missing values, it can be helpful to understand what can be learned from their presence. This can be considered a data science problem in itself, and to explore it, many of the same data science techniques can be used that we cover in other parts of this course.\n",
    "\n",
    "While we do not consider this issue further, some questions that can be useful to ask when confronted with a dataset with missing values:\n",
    "\n",
    "- Are there any fields that are commonly missing together? Are there particular patterns of missingness that are observed?\n",
    "- Can they be visualized?\n",
    "- Can the missingness of a field be modelled using the values of other fields? Which features were most informative for this?\n",
    "- Do the above relationships involving missingness offer any insight into the underlying cause of the missing data?\n",
    "- If so, can these be addressed or understood? For example, by discussing with the data provider or a domain expert?\n",
    "\n",
    "[This video](https://www.youtube.com/watch?v=PnNMfCRWL7k) describes some case studies where visualizing patterns of missing values in a dataset resulted in useful insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a02539c",
   "metadata": {},
   "source": [
    "## Relationships between variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec43c14",
   "metadata": {},
   "source": [
    "Let's now investigate the relationship between our variables variable of interest. This can help us understand how important these will become in our model. \n",
    "\n",
    "Notice that we have left a health variable within our selected set variables. This is done just as example for this exercise. Any variable under health should be treated as a candidate dependent measure rather than a predictor. These should correlate with SRH, but in a trivial manner. If we were to include these in the model then we would be assessing a person's ability to monitor their own health, which is not our research questions.\n",
    "\n",
    "From the data map, self-reported health is `Y11_Q42`. The derived health value indicating chronic health problems is `DV_Q43Q44` and we have renamed it as `ChronicHealth`. We can see for from the plots below that as the chronic health variable increases in severity self-reported health gets worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bd9b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(df_model, col=\"ChronicHealth\", sharey=False)\n",
    "g.map_dataframe(sns.histplot, 'SRH',binwidth=1,binrange=[0.5,5.5])\n",
    "    \n",
    "g.map_dataframe(plot_mean)\n",
    "g.set_axis_labels(\"SRH\", \"Count\")\n",
    "plt.show()\n",
    "\n",
    "print(df_uk[['ChronicHealth','SRH']].corr(method='spearman'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0883b725",
   "metadata": {},
   "source": [
    "We won't be using any health related variables in our model. Let's have a look at the other variables.\n",
    "\n",
    "We can use the seaborn `pairplot` function to plot multiple pairwise bivariate distributions in our dataset. This shows the relationship for all pair combination of variables in the DataFrame as a matrix of plots and the diagonal plots are the univariate plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c65a5b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# to more easily to differences let's cap the correlation cmap\n",
    "sns.pairplot(df_model[['SRH', 'DeprIndex', 'RuralUrban', 'AccomProblems', 'HouseholdSize',\n",
    "       'Children', 'ISCED', 'Education', 'SocialExclusionIndex',\n",
    "       'MentalWellbeingIndex', 'AgeCategory', 'Gender', 'MaritalStatus', 'ChronicHealth']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb26f31",
   "metadata": {},
   "source": [
    "As most our variables are ranks or categories, the plot matrix above might not be the best to visualise the relationships between variables. In this case is better to look at the rank correlations. Still, we take these with a pinch of salt because some of the variables are categorical rather than ordinal/numeric so the rank has little meaning (e.g. RuralUrban).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5562f38c",
   "metadata": {},
   "source": [
    "Some initial observations on the below correlation matrix:\n",
    "\n",
    "- Age correlates with a few variables. Especially SRH + Children\n",
    "- Lots of variables correlate with SRH.\n",
    "- DeprIndex, MentalWellbeing Index and Social Exclusion Index all correlate with one another.\n",
    "- DeprIndex correlates with quite a few varialbes (SRH, AccomProblems, Education). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4464837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to more easily to differences let's cap the correlation cmap\n",
    "f, axes = plt.subplots(figsize =(35,20))\n",
    "\n",
    "sns.heatmap(abs(df_model.drop(columns=['Country']).corr(method='spearman')), annot = True, vmin=0, vmax=1, center= 0., linewidths=3, linecolor='black',cmap= 'coolwarm')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02ea72c",
   "metadata": {},
   "source": [
    "Next we can go through each loose grouping of _material_, _occupational_ and _psychosocial_ to assess the suitability of variables to include in our model.\n",
    "\n",
    "### Material variables\n",
    "\n",
    "Let's examine the extent to which the _material_ variables are getting at representing similar things.\n",
    "\n",
    "Some initial thoughts:\n",
    "    - You would expect that has `DeprIndex` goes up `AccomProblems` will also go up since the persons cannot afford to remedy accommodation issues.\n",
    "    - `RuralUrban` only has two categories so doesn't lend itself to correlational analysis. Whether people are better off in the city, or the country depends on many factors (and varies between country).\n",
    "    - You would expect `HouseholdSize` and `Children` to be similar because `Children` counts towards household size (but `HouseholdSize` stops at >=4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b5d854",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mat = df_model[['DeprIndex','RuralUrban','AccomProblems','HouseholdSize','Children']]\n",
    "print(df_mat.corr(method='spearman'))\n",
    "\n",
    "df_mat=df_mat.groupby(by=['HouseholdSize','Children']).size().reset_index(name='counts')\n",
    "df_mat = df_mat.pivot(\"HouseholdSize\", \"Children\", \"counts\")\n",
    "\n",
    "sns.heatmap(df_mat, cmap=\"YlGnBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3c00eb",
   "metadata": {},
   "source": [
    "`HouseholdSize` does not appear to monotonically increase with `Children`. Probably the mediation here is `Age`. One can live alone but have five children who each have their own households. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3930d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mat=df_model[['DeprIndex','RuralUrban','AccomProblems','HouseholdSize','Children']].groupby(by=['DeprIndex','AccomProblems']).size().reset_index(name='counts')\n",
    "df_mat = df_mat.pivot(\"DeprIndex\", \"AccomProblems\", \"counts\")\n",
    "print(df_mat)\n",
    "# 0,0 will overwhelm the heatmap. Let's cap it.\n",
    "sns.heatmap(df_mat, cmap=\"YlGnBu\", vmax=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7289ae",
   "metadata": {},
   "source": [
    "There is a bias for zero accommodation problems but as deprivation increases the amount of accommodation problems tends to increase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a564dd3e",
   "metadata": {},
   "source": [
    "### Self reported health for the UK\n",
    "\n",
    "One thing we haven't done so far is have a look at the full SRH distribution for the UK. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546db9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2, figsize=(12,5))\n",
    "sns.histplot(data=df_uk, x='SRH', ax=axes[0],binwidth=1,binrange=[0.5,5.5])\n",
    "sns.histplot(data=df_uk, x='DeprIndex', ax=axes[1],binwidth=1,binrange=[0.5,6.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e48137",
   "metadata": {},
   "source": [
    "You can see that in the UK dataset, as with the global dataset, most of `DeprIndex` responses were zero (right graph above). In the left panel we have SRH. The responses here are:\n",
    "- 1: Very good\n",
    "- 2: Good\n",
    "- 3: Fair\n",
    "- 4: Bad\n",
    "- 5: Very Bad.  \n",
    "\n",
    "The positive skew (i.e. the mean will be to the right of the median) shows that participants felt more healthy than unhealthy. \n",
    "\n",
    "The paper uses the 2003 EQLS dataset which has the answers of [\"excellent”, “very good”, “good”, “fair”, “poor”]. The variable was dichotomised for ease of use with logistic regression as “good” health [\"excellent\", \"very good\", \"good\"] and “poor” health [\"fair\", \"poor\"]. \n",
    "\n",
    "Here we have different names of the responses. If we must dichotomise then the debate is around whether to categorise \"fair\" as good or bad health, since arguably the word semantically means good health rather than poor health. Let's follow the paper and have a 3-2 split with (\"bad\", \"very bad\") comprising the negative group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21456c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
