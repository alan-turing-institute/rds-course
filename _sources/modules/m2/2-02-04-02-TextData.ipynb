{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84e19226",
   "metadata": {},
   "source": [
    "# 2.2.4.2 Text data\n",
    "\n",
    "We'll often want to manipulate text data (strings) in Python.\n",
    "There are many handy libraries for helping us do this, some of which allow some pretty complicated operations.\n",
    "Here, we'll show some basic processing.\n",
    "\n",
    "## Inconsistencies\n",
    "\n",
    "Strings have their own particular array of consistency issues, such as inconsistent capitalisation and extraneous whitespace.\n",
    "\n",
    "Fortunately, python gives us some handy [built-in functionality](https://docs.python.org/3/library/stdtypes.html#string-methods) for dealing with some of these issues.\n",
    "\n",
    "We'll make note of a few of these methods, below.\n",
    "\n",
    "### `str.upper()` and `str.lower()`\n",
    "\n",
    "The `str.upper()` and `str.lower()` methods will take a given string and return a copy as a solely uppercase or lowercase string. E.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "270fd63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upper: FOO\n",
      "lower: foo\n"
     ]
    }
   ],
   "source": [
    "print(f\"upper: {'Foo'.upper()}\")\n",
    "print(f\"lower: {'Foo'.lower()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15b9cb4",
   "metadata": {},
   "source": [
    "These methods can be useful for ensuring consistency when casing is not important in your data.\n",
    "\n",
    "### `str.strip()`\n",
    "\n",
    "The `str.strip()` method (and its companions, `str.lstrip` and `str.rstrip()`) return a copy, stripping leading and trailing characters (default to whitespace) from a string. E.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ba94f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stripped: 'foo bar'\n",
      "left stripped: 'foo bar '\n",
      "right stripped: ' foo bar'\n"
     ]
    }
   ],
   "source": [
    "stripped = \" foo bar \".strip()\n",
    "\n",
    "print(f\"stripped: '{stripped}'\")\n",
    "lstripped = \" foo bar \".lstrip() # strip left\n",
    "print(f\"left stripped: '{lstripped}'\")\n",
    "\n",
    "rstripped = \" foo bar \".rstrip() # strip right\n",
    "print(f\"right stripped: '{rstripped}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2129a85e",
   "metadata": {},
   "source": [
    "### Spelling is tricky\n",
    "\n",
    "The methods we've talked about so far don't address things like misspelling/typos (a common data input concern).\n",
    "\n",
    "In a relatively simple scenario, with categorical data encoded as strings, you might be able to spot these by checking for all unique values in your data. E.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17b09431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'apple', 'aple', 'orange', 'grapefruit', 'pear'}\n"
     ]
    }
   ],
   "source": [
    "my_favourite_fruit_data = [\"apple\", \"apple\", \"pear\", \"orange\", \"aple\", \"orange\", \"grapefruit\"]\n",
    "print(set(my_favourite_fruit_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b0e0f1",
   "metadata": {},
   "source": [
    "## Splitting\n",
    "\n",
    "We'll also commonly want to split a string based on a particular delimiter or separator.\n",
    "For example, we may wish to split a string of text into individual words, using any whitespace separator.\n",
    "\n",
    "We can use the `str.split(sep=None, maxsplit=-1)` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26f82e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'is', 'some', 'text']\n",
      "['this,', 'another', 'example,', 'is', 'some', 'more', 'text']\n"
     ]
    }
   ],
   "source": [
    "s = \"this is some text\".split() # whitespace is the default\n",
    "print(s)\n",
    "\n",
    "# however, be careful of punctuation\n",
    "s2 = \"this, another example, is some more text\".split()\n",
    "print(s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8142dc",
   "metadata": {},
   "source": [
    "We may also wish to split by separators other than whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d14648d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'banana', 'pear', 'peach']\n"
     ]
    }
   ],
   "source": [
    "s = \"apple#banana#pear#peach\".split(\"#\")\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd19c940",
   "metadata": {},
   "source": [
    "With this in mind, we could also use `str.split` for dealing with csv data. However, we'd need to be careful about commas inside quotes.\n",
    "It's generally more convenient to use libraries that already deal with this kind of thing, like Pandas!\n",
    "\n",
    "\n",
    "## Joining\n",
    "\n",
    "A bit like `str.split(sep=None, maxsplit=-1)` in reverse, `str.join(iterable)` allows us to join a list of strings together with a given separator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b62dcd19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a list of words\n"
     ]
    }
   ],
   "source": [
    "my_list = [\"a\", \"list\", \"of\", \"words\"]\n",
    "# join with a space separator\n",
    "s = \" \".join(my_list)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba25a0d",
   "metadata": {},
   "source": [
    "## Regular expressions\n",
    "\n",
    "[Regular expressions (regexps, regex)](https://en.wikipedia.org/wiki/Regular_expression) are character sequences that specify a search pattern, usually for a find and/or replace task on text data.\n",
    "\n",
    "Python's [regular expression](https://docs.python.org/3/library/re.html) module provides functionality similar to that offered in Perl.\n",
    "\n",
    "Regex can give us powerful string matching, beyond that of a simple exact string match. E.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5663d80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Spain', 'the', 'So', 'they']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "txt = \"The rain in Spain falls mainly on the plains. So they say, anyway.\"\n",
    "# find all words starting with upper case S or lower case t\n",
    "print(re.findall(r\"\\b[St]\\w+\", txt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dab5c7",
   "metadata": {},
   "source": [
    "## NLP Preprocessing\n",
    "\n",
    "In Natural Language Processing (NLP) tasks we often see some slightly more complicated preprocessing such as:\n",
    "\n",
    "- [Stemming and Lemmatisation](https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html) - reducing words to common base forms\n",
    "- Stop-word Removal - removing common words that carry little information\n",
    "- \"Vectorization\" - convert text to a meaningful numeric vector representation (e.g. [term frequency encoding](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer))\n",
    "\n",
    "There are some commonly used libraries for the above tasks, we recommend [NLTK](https://www.nltk.org/) and [scikit-learn](https://scikit-learn.org/stable/).\n",
    "\n",
    "\n",
    "## Pandas String Operations (`Series.str`)\n",
    "\n",
    "Pandas provides vectorized string functions for Series. Unless explicitly handled, NAs will stay as NA. See [here](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.html).\n",
    "\n",
    "E.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2b5322e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    AAA\n",
       "1    AAb\n",
       "2    AbA\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([\"aaa\", \"aab\", \"aba\"])\n",
    "# replace \"a\" with \"A\"\n",
    "s.str.replace(\"a\", \"A\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.10.3"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "source_map": [
   14,
   34,
   37,
   45,
   54,
   62,
   65,
   74,
   81,
   85,
   88,
   98,
   103,
   113,
   118,
   136
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}